{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74ac7c13-4c9d-4e2e-a2c4-ed84a69a6184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_scale after first conv1x1: 10.0\n",
      "combined_scale after second conv3x3: 11.0\n",
      "combined_scale after third conv1x1: 11.0\n",
      "combined_scale after adding skip connection: -1.0\n",
      "Golden::Brevitas:: [[[[  0   0   0 ... 255 232   0]\n",
      "   [  0  16   0 ...   0 255   0]\n",
      "   [  0 240 255 ...   0  24 172]\n",
      "   ...\n",
      "   [255 254 255 ... 210   0   0]\n",
      "   [  0 206   0 ...   0   0   0]\n",
      "   [  0 192   0 ... 130 242   0]]\n",
      "\n",
      "  [[  0   0   0 ...   0 174 110]\n",
      "   [  0 164   0 ...   0   0 104]\n",
      "   [  0 166   0 ... 220  74  34]\n",
      "   ...\n",
      "   [250   0 138 ... 122   0   0]\n",
      "   [164   0  44 ...   0   0   0]\n",
      "   [  0   0 104 ...   0   0 238]]\n",
      "\n",
      "  [[168 228 132 ... 194   0 254]\n",
      "   [ 60   0  66 ...   0   0 194]\n",
      "   [  0   0 124 ...   0  64 255]\n",
      "   ...\n",
      "   [250   0   0 ...  74  74   0]\n",
      "   [254   0   0 ... 112   0 255]\n",
      "   [  0 138   0 ...   0   0   0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  0 230   0 ...   0  10 252]\n",
      "   [114   0   0 ... 168   0   0]\n",
      "   [  8   0   0 ...   0 226 132]\n",
      "   ...\n",
      "   [  0   0   0 ...   0 228  90]\n",
      "   [ 64   0   0 ...  16   0   0]\n",
      "   [238 134   0 ...  78 226 234]]\n",
      "\n",
      "  [[108   0   0 ...   0  36 255]\n",
      "   [  0   0  60 ...  30  14 220]\n",
      "   [ 68 204   0 ...   0 226   0]\n",
      "   ...\n",
      "   [  0  14 232 ...  22 248   0]\n",
      "   [238  98 206 ...   0  22   0]\n",
      "   [120 214 255 ...  12  98  38]]\n",
      "\n",
      "  [[  0   0 248 ...   0   0   0]\n",
      "   [  0   0  82 ...   0   0 255]\n",
      "   [ 14 255 242 ...   0 236 246]\n",
      "   ...\n",
      "   [220   0   0 ...   0 255   0]\n",
      "   [252   0 255 ...   0   0 154]\n",
      "   [  0 236  16 ...   0   0  26]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jacklo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\_tensor.py:1269: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10/core/TensorImpl.h:1791.)\n",
      "  return super().rename_(names)\n",
      "c:\\users\\jacklo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\brevitas\\export\\onnx\\standard\\manager.py:26: UserWarning: ONNX opset version set to 13, override with opset_version=\n",
      "  warnings.warn(f\"ONNX opset version set to {DEFAULT_OPSET}, override with {ka}=\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "ifm_mem_fmt shape (262144,)\n",
      "total_wts (69632,)\n",
      "AIE output::: tensor([[[[  0,   0,   0,  ..., 255, 232,   0],\n",
      "          [  0,  16,   0,  ...,   0, 255,   0],\n",
      "          [  0, 240, 255,  ...,   0,  24, 172],\n",
      "          ...,\n",
      "          [255, 254, 255,  ..., 210,   0,   0],\n",
      "          [  0, 206,   0,  ...,   0,   0,   0],\n",
      "          [  0, 192,   0,  ..., 130, 242,   0]],\n",
      "\n",
      "         [[  0,   0,   0,  ...,   0, 174, 110],\n",
      "          [  0, 164,   0,  ...,   0,   0, 104],\n",
      "          [  0, 166,   0,  ..., 220,  74,  34],\n",
      "          ...,\n",
      "          [250,   0, 138,  ..., 122,   0,   0],\n",
      "          [164,   0,  44,  ...,   0,   0,   0],\n",
      "          [  0,   0, 104,  ...,   0,   0, 238]],\n",
      "\n",
      "         [[168, 228, 132,  ..., 194,   0, 254],\n",
      "          [ 60,   0,  66,  ...,   0,   0, 194],\n",
      "          [  0,   0, 124,  ...,   0,  64, 255],\n",
      "          ...,\n",
      "          [250,   0,   0,  ...,  74,  74,   0],\n",
      "          [254,   0,   0,  ..., 112,   0, 255],\n",
      "          [  0, 138,   0,  ...,   0,   0,   0]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  0, 230,   0,  ...,   0,  10, 252],\n",
      "          [114,   0,   0,  ..., 168,   0,   0],\n",
      "          [  8,   0,   0,  ...,   0, 226, 132],\n",
      "          ...,\n",
      "          [  0,   0,   0,  ...,   0, 228,  90],\n",
      "          [ 64,   0,   0,  ...,  16,   0,   0],\n",
      "          [238, 134,   0,  ...,  78, 226, 234]],\n",
      "\n",
      "         [[108,   0,   0,  ...,   0,  36, 255],\n",
      "          [  0,   0,  60,  ...,  30,  14, 220],\n",
      "          [ 68, 204,   0,  ...,   0, 226,   0],\n",
      "          ...,\n",
      "          [  0,  14, 232,  ...,  22, 248,   0],\n",
      "          [238,  98, 206,  ...,   0,  22,   0],\n",
      "          [120, 214, 255,  ...,  12,  98,  38]],\n",
      "\n",
      "         [[  0,   0, 248,  ...,   0,   0,   0],\n",
      "          [  0,   0,  82,  ...,   0,   0, 255],\n",
      "          [ 14, 255, 242,  ...,   0, 236, 246],\n",
      "          ...,\n",
      "          [220,   0,   0,  ...,   0, 255,   0],\n",
      "          [252,   0, 255,  ...,   0,   0, 154],\n",
      "          [  0, 236,  16,  ...,   0,   0,  26]]]], dtype=torch.uint8)\n",
      "<class 'torch.Tensor'>\n",
      "<class 'brevitas.quant_tensor.QuantTensor'>\n",
      "difference:: tensor(0.0078, grad_fn=<MaxBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacklo\\AppData\\Local\\Temp\\ipykernel_501252\\2576071581.py:299: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:367.)\n",
      "  print(\"difference::\",torch.max(torch.abs(ofm_mem_fmt*inp_scale4 - q_bottleneck_out)))\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "sys.path.append(\"../misc\");\n",
    "from utils import DataShaper\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from brevitas.nn import QuantConv2d, QuantIdentity, QuantReLU\n",
    "from brevitas.quant.fixed_point import Int8ActPerTensorFixedPoint, Int8WeightPerTensorFixedPoint,Uint8ActPerTensorFixedPoint\n",
    "\n",
    "torch.manual_seed(0)\n",
    "design=\"bottleneck_cifar_split_scalar\"\n",
    "# design=\"bottleneck_cifar_split_vector\"\n",
    "# design=\"bottleneck_cifar_split_vector_casc\"\n",
    "# aie_teardown()\n",
    "sys.path.append(\"../../../utils\"); import xrtutils\n",
    "xclbin_path = os.path.abspath(\"../bottleneck_block/\"+design+\"/final.xclbin\")\n",
    "insts_path  = os.path.abspath(\"../bottleneck_block/\"+design+\"/insts.txt\")\n",
    "\n",
    "log_folder=\"log/log_\"+design\n",
    "\n",
    "enable_aie = True\n",
    "aie_is_setup = False\n",
    "enable_trace = False\n",
    "trace_file='traces/'+design+'.txt'\n",
    "\n",
    "app = None\n",
    "in_buf = None\n",
    "arg1_buf = None\n",
    "out_buf = None\n",
    "dtype_in  = np.dtype(\"int8\")\n",
    "dtype_out = np.dtype(\"uint8\")\n",
    "\n",
    "\n",
    "shape_in_act   = (32,32,32,8)\n",
    "shape_in_wts1  = (8,32,1,1,8,8) #out,in,ky,kx,in8,out8\n",
    "shape_in_wts2  = (8,8,3,3,8,8)  #out,in,ky,kx,in8,out8\n",
    "shape_in_wts3  = (32,8,1,1,8,8)   #out,in,ky,kx,in8,out8\n",
    "shape_total_wts= (69632,1)\n",
    "shape_out      = (32,32,32,8)\n",
    "\n",
    "trace_size = 8192\n",
    "\n",
    "def setup_aie(xclbin_path, insts_path, \n",
    "              in_0_shape, in_0_dtype,\n",
    "              in_1_shape, in_1_dtype, \n",
    "              out_buf_shape, out_buf_dtype,\n",
    "              enable_trace=False,\n",
    "              kernel_name=\"MLIR_AIE\"):\n",
    "    app = xrtutils.AIE_Application(xclbin_path, insts_path, kernel_name)\n",
    "    app.register_buffer(2, shape=in_0_shape, dtype=in_0_dtype)\n",
    "    app.register_buffer(3, shape=in_1_shape, dtype=in_1_dtype)\n",
    "    if enable_trace:\n",
    "      out_buf_len_bytes = np.prod(out_buf_shape) * np.dtype(out_buf_dtype).itemsize\n",
    "      out_buf_shape = (out_buf_len_bytes + trace_size, )\n",
    "      out_buf_dtype = np.uint8\n",
    "    app.register_buffer(4, shape=out_buf_shape, dtype=out_buf_dtype)\n",
    "    return app\n",
    "\n",
    "def extract_trace(out_buf, out_buf_shape, out_buf_dtype):\n",
    "    trace_size_words = trace_size//4\n",
    "    out_buf_flat = out_buf.reshape((-1,)).view(np.uint32)\n",
    "    output_prefix = out_buf_flat[:-trace_size_words].view(out_buf_dtype).reshape(out_buf_shape)\n",
    "    trace_suffix = out_buf_flat[-trace_size_words:]\n",
    "    return output_prefix, trace_suffix\n",
    "\n",
    "def write_out_trace(trace, file_name):\n",
    "    out_str = \"\\n\".join(f\"{i:0{8}x}\" \n",
    "                        for i in trace\n",
    "                        if i != 0)\n",
    "    with open(file_name, 'w') as f:\n",
    "      f.write(out_str)\n",
    "\n",
    "app = setup_aie(xclbin_path, insts_path,\n",
    "                            shape_in_act, dtype_in,      \n",
    "                            shape_total_wts,dtype_in,\n",
    "                            shape_out, dtype_out,enable_trace)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "if not os.path.exists(log_folder):\n",
    "    os.makedirs(log_folder)\n",
    "   \n",
    "    \n",
    "# input=torch.ones(64,32,32)\n",
    "input=torch.randn(1, 256,32,32)\n",
    "# image_name = f'./cifar_images/image_0.png'\n",
    "# img = Image.open(image_name)     \n",
    "# input_tensor = cifar_test_transform(img)\n",
    "# input = input_tensor.unsqueeze(0)\n",
    "# Use a separate QuantIdentity so that the quantized output can be fed to both layers\n",
    "\n",
    "num_classes=10\n",
    "\n",
    "# model =res.QuantSingleBottleneckModel2x_projected(num_classes)\n",
    "# saved_model_dict=torch.load(quant_weights,map_location=torch.device('cpu'))\n",
    "# model.load_state_dict(saved_model_dict)\n",
    "# model.eval()\n",
    "# # quant_wts1_int=model.layer1[1].conv1.quant_weight().int()\n",
    "# quant_wts1_int=model.layer1[1].conv1.quant_weight().int(float_datatype=True)\n",
    "# print(\"weight::::\",quant_wts1_int.size())\n",
    "# # qnt_wts_scale=model.layer1[1].conv1.quant_weight_scale()\n",
    "\n",
    "# quant_wts1_int=torch.div(quant_wts1_int, 10, rounding_mode='trunc')\n",
    "# # quant_wts1_float=torch.div(quant_wts1_float, 10, rounding_mode='trunc')\n",
    "\n",
    "ds = DataShaper()\n",
    "\n",
    "# try:\n",
    "for i in range (0,1): \n",
    "    class QuantBottleneck_projected(nn.Module):\n",
    "        expansion = 4\n",
    "        def __init__(self, in_planes=256, planes=64):\n",
    "            super(QuantBottleneck_projected, self).__init__()\n",
    "            self.quant_id_1 = QuantIdentity(act_quant=Int8ActPerTensorFixedPoint,bit_width=8, return_quant_tensor=True) \n",
    "            self.conv1 = QuantConv2d(in_planes, planes, kernel_size=1,bit_width=8,weight_bit_width=8, bias=False, weight_quant=Int8WeightPerTensorFixedPoint, return_quant_tensor=True)\n",
    "            self.conv2 = QuantConv2d(planes, planes, kernel_size=3,bit_width=8,weight_bit_width=8, bias=False,padding=1,padding_mode ='zeros', weight_quant=Int8WeightPerTensorFixedPoint, return_quant_tensor=True)\n",
    "            self.conv3 = QuantConv2d(planes, self.expansion *planes, kernel_size=1,bit_width=8,weight_bit_width=8, bias=False,weight_quant=Int8WeightPerTensorFixedPoint, return_quant_tensor=True)\n",
    "            self.relu1 = QuantReLU(act_quant=Uint8ActPerTensorFixedPoint ,bit_width=8, return_quant_tensor=True)\n",
    "            self.relu2 = QuantReLU(act_quant=Uint8ActPerTensorFixedPoint ,bit_width=8, return_quant_tensor=True)\n",
    "            self.relu3 = QuantReLU(act_quant=Uint8ActPerTensorFixedPoint ,bit_width=8, return_quant_tensor=True)\n",
    "\n",
    "        def forward(self, x):\n",
    "            out_q = self.quant_id_1(x)\n",
    "            out = self.conv1(out_q)\n",
    "            out = self.relu1(out)\n",
    "            out = self.conv2(out)\n",
    "            out = self.relu2(out)\n",
    "            out = self.conv3(out)\n",
    "            out = self.quant_id_1(out)\n",
    "            out = out+out_q\n",
    "            out = self.relu3(out)\n",
    "            return out\n",
    "   \n",
    "    quant_bottleneck_model=QuantBottleneck_projected()\n",
    "    \n",
    "\n",
    "    \n",
    "    quant_conv1 = QuantConv2d(256, 64, kernel_size=1,bit_width=8,weight_bit_width=8, bias=False, weight_quant=Int8WeightPerTensorFixedPoint, return_quant_tensor=True)\n",
    "    quant_conv2 = QuantConv2d(64, 64, kernel_size=3,bit_width=8,weight_bit_width=8, bias=False,padding=1,padding_mode ='zeros', weight_quant=Int8WeightPerTensorFixedPoint, return_quant_tensor=True)\n",
    "    quant_conv3 = QuantConv2d(64, 256, kernel_size=1,bit_width=8,weight_bit_width=8, bias=False,weight_quant=Int8WeightPerTensorFixedPoint, return_quant_tensor=True)\n",
    "    \n",
    "    simple_conv1= nn.Conv2d(256, 64, kernel_size=1, bias=False)\n",
    "    simple_conv2= nn.Conv2d(64, 64, kernel_size=3,padding=1,padding_mode ='zeros', bias=False)\n",
    "    simple_conv3= nn.Conv2d(64, 256, kernel_size=1, bias=False)\n",
    "\n",
    "        # bit_width= for QuantIdentity, since it has no weight tensor\n",
    "    quant_id_1 = QuantIdentity(act_quant=Int8ActPerTensorFixedPoint,bit_width=8, return_quant_tensor=True) \n",
    "    quant_id_2 = QuantIdentity(act_quant=Uint8ActPerTensorFixedPoint, bit_width=8, return_quant_tensor=True)\n",
    "    quant_id_3 = QuantIdentity(act_quant=Uint8ActPerTensorFixedPoint, bit_width=8, return_quant_tensor=True)\n",
    "    quant_id_4 = QuantIdentity(act_quant=Uint8ActPerTensorFixedPoint, bit_width=8, return_quant_tensor=True)\n",
    "\n",
    "    quant_relu1 = QuantReLU(act_quant=Uint8ActPerTensorFixedPoint ,bit_width=8, return_quant_tensor=True)\n",
    "    quant_relu2 = QuantReLU(act_quant=Uint8ActPerTensorFixedPoint ,bit_width=8, return_quant_tensor=True)\n",
    "    quant_relu3 = QuantReLU(act_quant=Uint8ActPerTensorFixedPoint ,bit_width=8, return_quant_tensor=True)\n",
    "\n",
    "    quant_bottleneck_model.eval()\n",
    "    quant_id_1.eval()\n",
    "    quant_id_2.eval()\n",
    "    quant_id_3.eval()\n",
    "    quant_id_4.eval()\n",
    "    quant_conv1.eval()\n",
    "    quant_conv2.eval()\n",
    "    quant_conv3.eval()\n",
    "    quant_relu1.eval()\n",
    "    quant_relu2.eval()\n",
    "    quant_relu3.eval()\n",
    "    \n",
    "\n",
    "     # q_inp == int_inp * inp_scale\n",
    "\n",
    "    \n",
    "    inp_scale1 = quant_id_1.quant_act_scale()\n",
    "    inp_scale2 = quant_relu1.quant_act_scale()\n",
    "    inp_scale3= quant_relu2.quant_act_scale()\n",
    "    inp_scale4= quant_relu3.quant_act_scale()\n",
    "\n",
    "    weight_scale1 = quant_conv1.quant_weight_scale()\n",
    "    weight_scale2 = quant_conv2.quant_weight_scale()\n",
    "    weight_scale3 = quant_conv3.quant_weight_scale()\n",
    "\n",
    "    combined_scale1=-torch.log2(inp_scale1*weight_scale1/inp_scale2)\n",
    "    combined_scale2=-torch.log2(inp_scale2*weight_scale2/inp_scale3)\n",
    "    combined_scale3=-torch.log2(inp_scale3*weight_scale3/inp_scale1)\n",
    "    combined_scale4=-torch.log2(inp_scale1/inp_scale4)\n",
    "    print(\"combined_scale after first conv1x1:\",combined_scale1.item())\n",
    "    print(\"combined_scale after second conv3x3:\",combined_scale2.item())\n",
    "    print(\"combined_scale after third conv1x1:\",combined_scale3.item())\n",
    "    print(\"combined_scale after adding skip connection:\",(combined_scale4).item())\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    int_weight1 = quant_conv1.quant_weight().int(float_datatype=True)\n",
    "    int_weight2 = quant_conv2.quant_weight().int(float_datatype=True)\n",
    "    int_weight3 = quant_conv3.quant_weight().int(float_datatype=True)\n",
    "\n",
    "    # update class weights\n",
    "    quant_bottleneck_model.conv1.load_state_dict(quant_conv1.state_dict())\n",
    "    quant_bottleneck_model.conv2.load_state_dict(quant_conv2.state_dict())\n",
    "    quant_bottleneck_model.conv3.load_state_dict(quant_conv3.state_dict())\n",
    "    \n",
    "    simple_conv1.weight.data.copy_(int_weight1)\n",
    "    simple_conv2.weight.data.copy_(int_weight2)\n",
    "    simple_conv3.weight.data.copy_(int_weight3)\n",
    "\n",
    "    # m1_q_out1=quant_conv1(q_inp)\n",
    "    # m1_q_out2=quant_conv2(m1_q_out1)\n",
    "    # m1_q_out3=quant_conv3(m1_q_out2)\n",
    "    # m1_q_add=torch.add(q_inp,m1_q_out3 )\n",
    "    # m1_int_out_final = m1_q_add.int()\n",
    "\n",
    "    q_bottleneck_out=quant_bottleneck_model(input)\n",
    "    gold_out=q_bottleneck_out.int(float_datatype=True).data.numpy().astype(dtype_out)\n",
    "    print(\"Golden::Brevitas::\",gold_out)\n",
    "    from brevitas.export import export_onnx_qcdq\n",
    "    # ref_input = torch.ones(1, 3, 32, 32, device=\"cpu\", dtype=dtype)\n",
    "    export_onnx_qcdq(quant_bottleneck_model, input, log_folder+\"/\"+design+\".onnx\")\n",
    "    # Brevitas convolution\n",
    "    q_inp = quant_id_1(input)\n",
    "    int_inp = q_inp.int(float_datatype=True)\n",
    "    \n",
    "    m1_q_out1=quant_conv1(q_inp)\n",
    "    m1_q_ident2=quant_relu1(m1_q_out1)\n",
    "    m1_q_out2=quant_conv2(m1_q_ident2)\n",
    "    m1_q_ident3=quant_relu2(m1_q_out2)\n",
    "    m1_q_out3=quant_conv3(m1_q_ident3)\n",
    "    m1_q_out4 = quant_id_1(m1_q_out3)\n",
    "    # print(\"Before output add:::\",m1_q_out4.int(float_datatype=True))\n",
    "    m1_add_final=q_inp+m1_q_out4\n",
    "\n",
    "    m1_add_final_q = quant_relu3(m1_add_final)\n",
    "    # print(\"Brevitas standalone output:::\",m1_add_final_q.int(float_datatype=True))\n",
    "    \n",
    "    # Standard convolution \n",
    "    m2_int_out1 = simple_conv1(int_inp)\n",
    "    m2_int_out1_scaled = m2_int_out1 * weight_scale1 * inp_scale1\n",
    "    m2_int_ident2 = quant_id_2(m2_int_out1_scaled).int(float_datatype=True)\n",
    "    m2_int_out2 = simple_conv2(m2_int_ident2)\n",
    "    m2_int_out2_scaled = m2_int_out2 * weight_scale2 * inp_scale2\n",
    "    m2_int_ident3 = quant_id_3(m2_int_out2_scaled).int(float_datatype=True)\n",
    "    m2_int_out3 =simple_conv3(m2_int_ident3)\n",
    "    m2_int_out3_scaled = m2_int_out3 * weight_scale3 * inp_scale3\n",
    "    m2_int_out3_scaled_ident1=quant_id_1(m2_int_out3_scaled).int(float_datatype=True)\n",
    "    # print(\"Before output add:::\",m2_int_out3_scaled_ident1)\n",
    "    m2_final_add=m2_int_out3_scaled_ident1+int_inp\n",
    "    m2_final_add_scaled=m2_final_add*inp_scale1\n",
    "    m2_final_add_ident4=quant_id_4(m2_final_add_scaled).int(float_datatype=True)\n",
    "    # print(\"Standard conv::\",m2_final_add_ident4)\n",
    "    \n",
    "    \n",
    "    # print(\"Input:::\", int_inp)\n",
    "\n",
    "    # print(\"Final standard conv::\",m2_final_add)\n",
    "   \n",
    "    \n",
    "    before_input=int_inp.squeeze().data.numpy().astype(dtype_in)\n",
    "    # print(before_input)\n",
    "    before_input.tofile(log_folder+\"/before_ifm_mem_fmt_1x1.txt\", sep=\",\", format=\"%d\")\n",
    "    # ifm_mem_fmt = ds.reorder_mat(int_inp.squeeze().data.numpy().astype(dtype_in),'YCX' , 'CYX' )\n",
    "    # ifm_mem_fmt = ds.reorder_mat(before_input,'YCX' , 'CYX' )\n",
    "    ifm_mem_fmt = ds.reorder_mat(before_input,'YCXC8' , 'CYX' )\n",
    "    # print(\"Input after:::\",ifm_mem_fmt.reshape((32,256, 32)))\n",
    "    ifm_mem_fmt.tofile(log_folder+\"/after_ifm_mem_fmt_1x1.txt\", sep=\",\", format=\"%d\")\n",
    "    print(\"ifm_mem_fmt shape\",ifm_mem_fmt.shape)\n",
    "    # wts1 = ds.reorder_mat(int_weight1.data.numpy().astype(dtype_in),'OIYX' , 'OIYX' )\n",
    "    # wts2 = ds.reorder_mat(int_weight2.data.numpy().astype(dtype_in),'OIYX' , 'OIYX' )\n",
    "    # wts3 = ds.reorder_mat(int_weight3.data.numpy().astype(dtype_in),'OIYX' , 'OIYX' )\n",
    "    wts1 = ds.reorder_mat(int_weight1.data.numpy().astype(dtype_in),'OIYXI8O8' , 'OIYX' )\n",
    "    wts2 = ds.reorder_mat(int_weight2.data.numpy().astype(dtype_in),'OIYXI8O8' , 'OIYX' )\n",
    "    wts3 = ds.reorder_mat(int_weight3.data.numpy().astype(dtype_in),'OIYXI8O8' , 'OIYX' )\n",
    "    \n",
    "    total_wts=np.concatenate((wts1,wts2,wts3),axis=None)\n",
    "    total_wts.tofile(log_folder+\"/weights_mem_fmt_final.txt\", sep=\",\", format=\"%d\")\n",
    "    print(\"total_wts\", total_wts.shape)\n",
    "    for i in range (0,2):\n",
    "        app.buffers[2].write(ifm_mem_fmt)# input's standard format CYX | scalar YCX\n",
    "        app.buffers[3].write(total_wts) # wts's standard format OIYX | scalar OIYX\n",
    "        # app.buffers[3].write(int_weight2.data.numpy().astype(dtype_in),offset=2048) # wts's standard format OIYX | scalar OIYX\n",
    "        app.run()\n",
    "        output3= app.buffers[4].read()\n",
    "        if enable_trace:\n",
    "            output3, trace = extract_trace(output3, shape_out, dtype_out)\n",
    "            write_out_trace(trace, trace_file)\n",
    "    # temp_out=output3.reshape(32,256, 32)\n",
    "    # ofm_mem_fmt = temp_out.swapaxes(0,1)\n",
    "    temp_out    = output3.reshape(32,32,32,8)\n",
    "    temp2_out   = ds.reorder_mat( temp_out, 'CDYX','YCXD' )\n",
    "    ofm_mem_fmt = temp2_out.reshape(256,32,32)   \n",
    "    ofm_mem_fmt.tofile(log_folder+\"/after_ofm_mem_fmt_final.txt\", sep=\",\", format=\"%d\")\n",
    "    \n",
    "    ofm_mem_fmt=torch.from_numpy(ofm_mem_fmt).unsqueeze(0)\n",
    "    # print(\"Input::\",input)\n",
    "    print(\"AIE output:::\",ofm_mem_fmt)\n",
    "    print(type(ofm_mem_fmt))\n",
    "    print(type(q_bottleneck_out))\n",
    "    print(\"difference::\",torch.max(torch.abs(ofm_mem_fmt*inp_scale4 - q_bottleneck_out)))\n",
    "    assert(np.allclose(ofm_mem_fmt, gold_out, rtol=0, atol=2.))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e5c9e7e-997d-4e29-87e9-6dc4f69113a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2149842944 3690978303 3690978303 ... 3690978303 3690978303 3690978303]\n"
     ]
    }
   ],
   "source": [
    "if (enable_trace):\n",
    "    print(trace)\n",
    "else:\n",
    "    print (\"tracing not enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31861e3-73d3-4197-b802-195c1573eedd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
