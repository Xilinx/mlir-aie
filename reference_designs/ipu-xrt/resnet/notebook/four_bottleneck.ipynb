{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eefc1d8-b573-45f1-8d18-f25a0a4ec980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../misc\")\n",
    "from utils import DataShaper\n",
    "import os\n",
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from brevitas.nn import QuantConv2d, QuantIdentity, QuantReLU\n",
    "from brevitas.quant.fixed_point import (\n",
    "    Int8ActPerTensorFixedPoint,\n",
    "    Int8WeightPerTensorFixedPoint,\n",
    "    Uint8ActPerTensorFixedPoint,\n",
    ")\n",
    "\n",
    "ds = DataShaper()\n",
    "torch.manual_seed(0)\n",
    "design = \"four_bottleneck\"\n",
    "# aie_teardown()\n",
    "sys.path.append(\"../../../utils\")\n",
    "import xrtutils\n",
    "\n",
    "xclbin_path = os.path.abspath(\"../bottleneck_block/\" + design + \"/build/final.xclbin\")\n",
    "insts_path = os.path.abspath(\"../bottleneck_block/\" + design + \"/build/insts.txt\")\n",
    "\n",
    "log_folder = \"log/log_\" + design\n",
    "if not os.path.exists(log_folder):\n",
    "    os.makedirs(log_folder)\n",
    "enable_aie = True\n",
    "aie_is_setup = False\n",
    "enable_trace = False\n",
    "trace_file = \"traces/trace.txt\"\n",
    "\n",
    "app = None\n",
    "in_buf = None\n",
    "arg1_buf = None\n",
    "out_buf = None\n",
    "dtype_in = np.dtype(\"int8\")\n",
    "dtype_wts = np.dtype(\"int8\")\n",
    "dtype_out = np.dtype(\"uint8\")\n",
    "\n",
    "shape_in_act = (32, 8, 32, 8)  #'YCXC8' , 'CYX'\n",
    "# shape_in_wts1  = (8,8,1,1,8,8) #out,in,ky,kx,in8,out8\n",
    "# shape_in_wts2  = (8,8,3,3,8,8)  #out,in,ky,kx,in8,out8\n",
    "# shape_in_wts3  = (32,8,1,1,8,8)   #out,in,ky,kx,in8,out8\n",
    "# shape_in_wts_skip  = (8,32,1,1,8,8) #out,in,ky,kx,in8,out8\n",
    "shape_total_wts = (282624, 1)\n",
    "shape_out = (32, 32, 32, 8)\n",
    "\n",
    "trace_size = 8192\n",
    "\n",
    "\n",
    "def setup_aie(\n",
    "    xclbin_path,\n",
    "    insts_path,\n",
    "    in_0_shape,\n",
    "    in_0_dtype,\n",
    "    in_1_shape,\n",
    "    in_1_dtype,\n",
    "    out_buf_shape,\n",
    "    out_buf_dtype,\n",
    "    enable_trace=False,\n",
    "    kernel_name=\"MLIR_AIE\",\n",
    "):\n",
    "    app = xrtutils.AIE_Application(xclbin_path, insts_path, kernel_name)\n",
    "    app.register_buffer(2, shape=in_0_shape, dtype=in_0_dtype)\n",
    "    app.register_buffer(3, shape=in_1_shape, dtype=in_1_dtype)\n",
    "    if enable_trace:\n",
    "        out_buf_len_bytes = np.prod(out_buf_shape) * np.dtype(out_buf_dtype).itemsize\n",
    "        out_buf_shape = (out_buf_len_bytes + trace_size,)\n",
    "        out_buf_dtype = np.uint8\n",
    "    app.register_buffer(4, shape=out_buf_shape, dtype=out_buf_dtype)\n",
    "    return app\n",
    "\n",
    "\n",
    "def extract_trace(out_buf, out_buf_shape, out_buf_dtype):\n",
    "    trace_size_words = trace_size // 4\n",
    "    out_buf_flat = out_buf.reshape((-1,)).view(np.uint32)\n",
    "    output_prefix = (\n",
    "        out_buf_flat[:-trace_size_words].view(out_buf_dtype).reshape(out_buf_shape)\n",
    "    )\n",
    "    trace_suffix = out_buf_flat[-trace_size_words:]\n",
    "    return output_prefix, trace_suffix\n",
    "\n",
    "\n",
    "def write_out_trace(trace, file_name):\n",
    "    out_str = \"\\n\".join(f\"{i:0{8}x}\" for i in trace if i != 0)\n",
    "    with open(file_name, \"w\") as f:\n",
    "        f.write(out_str)\n",
    "\n",
    "\n",
    "app = setup_aie(\n",
    "    xclbin_path,\n",
    "    insts_path,\n",
    "    shape_in_act,\n",
    "    dtype_in,\n",
    "    shape_total_wts,\n",
    "    dtype_wts,\n",
    "    shape_out,\n",
    "    dtype_out,\n",
    "    enable_trace,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a5357e2-a746-42fe-9dda-20d2029d228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "from brevitas.nn import QuantConv2d, QuantIdentity, QuantReLU\n",
    "from brevitas.quant.fixed_point import (\n",
    "    Int8ActPerTensorFixedPoint,\n",
    "    Int8WeightPerTensorFixedPoint,\n",
    "    Uint8ActPerTensorFixedPoint,\n",
    ")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "def init_pad_input(x, input_channels, desired_channels=4):\n",
    "    padding = torch.zeros(1, input_channels * (desired_channels - 1), 32, 32)\n",
    "    return torch.cat((x, padding), 1)\n",
    "\n",
    "\n",
    "# try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bb5f126-1051-4a4e-bf7b-cc7f7e0b92c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________POST PTQ SCALES_________\n",
      "init_scale: tensor(0.0078)\n",
      "block_0_relu1: tensor(0.0039)\n",
      "block_0_relu2: tensor(0.0039)\n",
      "block_0_relu3: tensor(0.0039)\n",
      "block_0_weight_scale1: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "block_0_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_0_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "block_0_weight_scale_skip: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "block_1_quant_add_1: tensor(0.0039)\n",
      "block_1_relu1: tensor(0.0039)\n",
      "block_1_relu2: tensor(0.0039)\n",
      "block_1_relu3: tensor(0.0039)\n",
      "block_1_weight_scale1: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_1_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_1_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "block_2_quant_add_1: tensor(0.0039)\n",
      "block_2_relu1: tensor(0.0039)\n",
      "block_2_relu2: tensor(0.0039)\n",
      "block_2_relu3: tensor(0.0039)\n",
      "block_2_weight_scale1: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_2_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_2_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "block_3_quant_add_1: tensor(0.0039)\n",
      "block_3_relu1: tensor(0.0039)\n",
      "block_3_relu2: tensor(0.0039)\n",
      "block_3_relu3: tensor(0.0039)\n",
      "block_3_weight_scale1: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_3_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_3_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "combined_scale block0 after first conv1x1: 9.0\n",
      "combined_scale block0 after second conv3x3: 11.0\n",
      "combined_scale block0 after third conv1x1: 11.0\n",
      "combined_scale block0 after adding skip connection: -1.0\n",
      "combined_scale block0 after skip conv1x1: 10.0\n",
      "--------------------------------------------------------------\n",
      "combined_scale block1 after first conv1x1: 11.0\n",
      "combined_scale block1 after second conv3x3: 11.0\n",
      "combined_scale block1 after third conv1x1: 10.0\n",
      "combined_scale block1 after adding skip connection: -0.0\n",
      "--------------------------------------------------------------\n",
      "combined_scale block2 after first conv1x1: 11.0\n",
      "combined_scale block2 after second conv3x3: 11.0\n",
      "combined_scale block2 after third conv1x1: 10.0\n",
      "combined_scale block2 after adding skip connection: -0.0\n",
      "--------------------------------------------------------------\n",
      "combined_scale block3 after first conv1x1: 11.0\n",
      "combined_scale block3 after second conv3x3: 11.0\n",
      "combined_scale block3 after third conv1x1: 10.0\n",
      "combined_scale block3 after adding skip connection: -0.0\n",
      "Golden::Brevitas:: [[[[ 92   3  80 ...  64   6  82]\n",
      "   [152 106  15 ... 165  69  14]\n",
      "   [  0   1   3 ...   6 242 106]\n",
      "   ...\n",
      "   [ 17 106 153 ...   0  13 103]\n",
      "   [246   9  61 ...   9  41  13]\n",
      "   [ 23  10  12 ...  19   0   3]]\n",
      "\n",
      "  [[ 32  26   3 ...   3  82   1]\n",
      "   [  2  68   0 ...   6   0 158]\n",
      "   [  5  24   0 ...   0 131   1]\n",
      "   ...\n",
      "   [ 12   4   0 ...   0   0   0]\n",
      "   [ 95   1  30 ...  56 125  72]\n",
      "   [158   2   0 ...   3   0   2]]\n",
      "\n",
      "  [[250   5   7 ... 182   3  35]\n",
      "   [  5  10   0 ... 188  83 116]\n",
      "   [  8  12   8 ...  86 104   6]\n",
      "   ...\n",
      "   [ 12   0   8 ... 198  71   8]\n",
      "   [129 197   8 ...   3  73   7]\n",
      "   [ 39  10   3 ...  11  20   2]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[101   9   0 ...   7   8  16]\n",
      "   [  6   8   0 ...  66  19  11]\n",
      "   [ 12 118  14 ...   4  36  88]\n",
      "   ...\n",
      "   [  6  12   0 ...  12 103  11]\n",
      "   [109  18  13 ...  16  83  24]\n",
      "   [117  42  97 ...  14  77  14]]\n",
      "\n",
      "  [[  0   0   8 ...   0  25   0]\n",
      "   [  2 143   0 ... 125  67  11]\n",
      "   [  4   0   6 ...  11  42   0]\n",
      "   ...\n",
      "   [  0  92   0 ...  53  92 189]\n",
      "   [ 78   0   2 ...   3 147  67]\n",
      "   [ 72  44  56 ...   0   0   0]]\n",
      "\n",
      "  [[  0  35  15 ...   0   0 152]\n",
      "   [ 55  76  81 ...  90  16   4]\n",
      "   [136 142  50 ...  25   4 132]\n",
      "   ...\n",
      "   [  0   0 126 ...   4 155 218]\n",
      "   [112  65  45 ...  45   0   4]\n",
      "   [  4   6  48 ...   2   8   5]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gagan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\brevitas\\export\\onnx\\standard\\manager.py:26: UserWarning: ONNX opset version set to 13, override with opset_version=\n",
      "  warnings.warn(f\"ONNX opset version set to {DEFAULT_OPSET}, override with {ka}=\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "total_wts (143360,)\n",
      "AIE output::: tensor([[[[ 92,   3,  80,  ...,  64,   6,  82],\n",
      "          [153, 106,  15,  ..., 165,  69,  14],\n",
      "          [  0,   1,   3,  ...,   6, 242, 106],\n",
      "          ...,\n",
      "          [ 17, 106, 154,  ...,   0,  13, 102],\n",
      "          [246,   9,  61,  ...,   9,  41,  13],\n",
      "          [ 23,  10,  12,  ...,  19,   0,   3]],\n",
      "\n",
      "         [[ 32,  26,   3,  ...,   3,  82,   1],\n",
      "          [  2,  68,   0,  ...,   6,   0, 158],\n",
      "          [  6,  25,   0,  ...,   0, 131,   1],\n",
      "          ...,\n",
      "          [ 13,   4,   1,  ...,   0,   0,   0],\n",
      "          [ 95,   1,  30,  ...,  56, 125,  72],\n",
      "          [158,   2,   0,  ...,   2,   0,   2]],\n",
      "\n",
      "         [[250,   5,   8,  ..., 182,   4,  35],\n",
      "          [  5,  10,   0,  ..., 188,  83, 116],\n",
      "          [  8,  12,   9,  ...,  85, 104,   5],\n",
      "          ...,\n",
      "          [ 13,   1,   8,  ..., 199,  71,   8],\n",
      "          [130, 197,   8,  ...,   3,  73,   7],\n",
      "          [ 39,  10,   3,  ...,  11,  20,   2]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[101,   9,   0,  ...,   7,   8,  16],\n",
      "          [  6,   8,   1,  ...,  66,  19,  12],\n",
      "          [ 12, 118,  14,  ...,   4,  36,  88],\n",
      "          ...,\n",
      "          [  6,  12,   0,  ...,  11, 103,  11],\n",
      "          [109,  18,  13,  ...,  16,  83,  24],\n",
      "          [117,  42,  97,  ...,  14,  77,  13]],\n",
      "\n",
      "         [[  0,   0,   8,  ...,   0,  25,   0],\n",
      "          [  2, 143,   0,  ..., 125,  67,  11],\n",
      "          [  4,   0,   6,  ...,  11,  43,   0],\n",
      "          ...,\n",
      "          [  0,  92,   0,  ...,  52,  92, 189],\n",
      "          [ 78,   0,   2,  ...,   3, 147,  67],\n",
      "          [ 72,  44,  56,  ...,   0,   0,   0]],\n",
      "\n",
      "         [[  0,  35,  15,  ...,   0,   0, 152],\n",
      "          [ 55,  76,  81,  ...,  90,  16,   4],\n",
      "          [135, 142,  50,  ...,  25,   4, 132],\n",
      "          ...,\n",
      "          [  0,   0, 126,  ...,   3, 155, 218],\n",
      "          [112,  65,  45,  ...,  45,   0,   4],\n",
      "          [  4,   6,  48,  ...,   2,   8,   5]]]], dtype=torch.uint8)\n",
      "<class 'torch.Tensor'>\n",
      "<class 'brevitas.quant_tensor.QuantTensor'>\n",
      "difference:: tensor(0.0156, grad_fn=<MaxBackward1>)\n",
      "rms:: tensor(0.0017, grad_fn=<SqrtBackward0>)\n",
      "_________POST PTQ SCALES_________\n",
      "init_scale: tensor(0.0078)\n",
      "block_0_relu1: tensor(0.0039)\n",
      "block_0_relu2: tensor(0.0039)\n",
      "block_0_relu3: tensor(0.0039)\n",
      "block_0_weight_scale1: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "block_0_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_0_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "block_0_weight_scale_skip: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "block_1_quant_add_1: tensor(0.0039)\n",
      "block_1_relu1: tensor(0.0039)\n",
      "block_1_relu2: tensor(0.0039)\n",
      "block_1_relu3: tensor(0.0039)\n",
      "block_1_weight_scale1: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_1_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_1_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "block_2_quant_add_1: tensor(0.0039)\n",
      "block_2_relu1: tensor(0.0039)\n",
      "block_2_relu2: tensor(0.0039)\n",
      "block_2_relu3: tensor(0.0039)\n",
      "block_2_weight_scale1: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_2_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_2_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "block_3_quant_add_1: tensor(0.0039)\n",
      "block_3_relu1: tensor(0.0039)\n",
      "block_3_relu2: tensor(0.0039)\n",
      "block_3_relu3: tensor(0.0039)\n",
      "block_3_weight_scale1: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_3_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_3_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "combined_scale block0 after first conv1x1: 9.0\n",
      "combined_scale block0 after second conv3x3: 11.0\n",
      "combined_scale block0 after third conv1x1: 11.0\n",
      "combined_scale block0 after adding skip connection: -1.0\n",
      "combined_scale block0 after skip conv1x1: 10.0\n",
      "--------------------------------------------------------------\n",
      "combined_scale block1 after first conv1x1: 11.0\n",
      "combined_scale block1 after second conv3x3: 11.0\n",
      "combined_scale block1 after third conv1x1: 10.0\n",
      "combined_scale block1 after adding skip connection: -0.0\n",
      "--------------------------------------------------------------\n",
      "combined_scale block2 after first conv1x1: 11.0\n",
      "combined_scale block2 after second conv3x3: 11.0\n",
      "combined_scale block2 after third conv1x1: 10.0\n",
      "combined_scale block2 after adding skip connection: -0.0\n",
      "--------------------------------------------------------------\n",
      "combined_scale block3 after first conv1x1: 11.0\n",
      "combined_scale block3 after second conv3x3: 11.0\n",
      "combined_scale block3 after third conv1x1: 10.0\n",
      "combined_scale block3 after adding skip connection: -0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_24072\\3583113412.py:317: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:367.)\n",
      "  print(\"difference::\",torch.max(torch.abs(ofm_mem_fmt*block_3_relu_3 - q_bottleneck_out)))\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_24072\\3583113412.py:328: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:367.)\n",
      "  sq_abs = torch.square(torch.abs(ofm_mem_fmt*block_3_relu_3 - q_bottleneck_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden::Brevitas:: [[[[ 95   5   0 ...   3   0  35]\n",
      "   [  0   1  12 ...  27 185   0]\n",
      "   [ 84  47 105 ...   0 138  61]\n",
      "   ...\n",
      "   [  0  81   6 ...  56   6   9]\n",
      "   [  0   0   0 ...   0   0   0]\n",
      "   [  0   0  48 ...   5  64   8]]\n",
      "\n",
      "  [[  4  74 184 ... 106   6   4]\n",
      "   [  4  49  56 ... 101   9  16]\n",
      "   [ 18  41  12 ... 138  85  12]\n",
      "   ...\n",
      "   [137   7   6 ...  82  13  37]\n",
      "   [ 15  68  68 ...  12   6  95]\n",
      "   [ 85 104   9 ... 175  26 170]]\n",
      "\n",
      "  [[  0   1  62 ...  19   0   4]\n",
      "   [  6  17   0 ...  19   0  39]\n",
      "   [  8   0  27 ...  21  23  14]\n",
      "   ...\n",
      "   [ 13  17  45 ...  13   0 164]\n",
      "   [ 14   3 105 ...  29  13  69]\n",
      "   [ 52 226  34 ... 147  94  99]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 43  53  50 ...  15  85  64]\n",
      "   [ 10 122  26 ...  60  23  89]\n",
      "   [  6  85  23 ... 105  10  16]\n",
      "   ...\n",
      "   [  7  99  64 ...  17  64  10]\n",
      "   [ 16  11 165 ...  25 188  11]\n",
      "   [ 18  96 154 ...  13  25   7]]\n",
      "\n",
      "  [[ 86  14  14 ...  19  10 249]\n",
      "   [ 20  35  57 ...  21  21   7]\n",
      "   [  8  12   3 ... 123   9  35]\n",
      "   ...\n",
      "   [ 51  70 108 ...  12  16  20]\n",
      "   [  7  45  18 ... 141 129   7]\n",
      "   [  9   8 101 ...   9  17 106]]\n",
      "\n",
      "  [[  0   0 103 ...   6   2   9]\n",
      "   [  0  23   5 ...   0  20  29]\n",
      "   [  3 152   2 ... 112   0  15]\n",
      "   ...\n",
      "   [  0  61   0 ...   4  10 176]\n",
      "   [  4   0  96 ... 231   2 105]\n",
      "   [  0  86   0 ... 184   0  33]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gagan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\brevitas\\export\\onnx\\standard\\manager.py:26: UserWarning: ONNX opset version set to 13, override with opset_version=\n",
      "  warnings.warn(f\"ONNX opset version set to {DEFAULT_OPSET}, override with {ka}=\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "total_wts (143360,)\n",
      "AIE output::: tensor([[[[ 95,   5,   0,  ...,   3,   0,  35],\n",
      "          [  0,   1,  12,  ...,  27, 185,   0],\n",
      "          [ 83,  47, 105,  ...,   0, 138,  61],\n",
      "          ...,\n",
      "          [  0,  81,   6,  ...,  56,   7,   9],\n",
      "          [  0,   0,   0,  ...,   0,   0,   0],\n",
      "          [  0,   0,  48,  ...,   4,  64,   7]],\n",
      "\n",
      "         [[  4,  74, 184,  ..., 106,   6,   4],\n",
      "          [  4,  49,  56,  ..., 101,   9,  16],\n",
      "          [ 18,  41,  12,  ..., 138,  84,  11],\n",
      "          ...,\n",
      "          [138,   6,   5,  ...,  82,  12,  37],\n",
      "          [ 15,  68,  68,  ...,  12,   5,  95],\n",
      "          [ 85, 104,   9,  ..., 175,  26, 170]],\n",
      "\n",
      "         [[  0,   1,  62,  ...,  20,   0,   4],\n",
      "          [  6,  17,   0,  ...,  19,   0,  39],\n",
      "          [  8,   0,  27,  ...,  21,  23,  15],\n",
      "          ...,\n",
      "          [ 13,  17,  45,  ...,  13,   0, 164],\n",
      "          [ 14,   3, 105,  ...,  29,  13,  69],\n",
      "          [ 54, 225,  34,  ..., 149,  93,  99]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 43,  53,  50,  ...,  14,  85,  65],\n",
      "          [ 10, 122,  26,  ...,  60,  23,  89],\n",
      "          [  6,  85,  23,  ..., 105,  10,  16],\n",
      "          ...,\n",
      "          [  7,  98,  64,  ...,  17,  64,  10],\n",
      "          [ 16,  12, 165,  ...,  25, 189,  11],\n",
      "          [ 18,  96, 155,  ...,  13,  26,   7]],\n",
      "\n",
      "         [[ 86,  14,  14,  ...,  19,  10, 250],\n",
      "          [ 20,  35,  57,  ...,  22,  21,   7],\n",
      "          [  8,  12,   3,  ..., 123,   9,  35],\n",
      "          ...,\n",
      "          [ 51,  70, 108,  ...,  12,  16,  20],\n",
      "          [  7,  45,  18,  ..., 141, 129,   7],\n",
      "          [  9,   8, 101,  ...,   9,  17, 106]],\n",
      "\n",
      "         [[  0,   0, 102,  ...,   6,   2,   9],\n",
      "          [  0,  23,   5,  ...,   0,  21,  29],\n",
      "          [  3, 152,   2,  ..., 112,   0,  16],\n",
      "          ...,\n",
      "          [  0,  61,   0,  ...,   4,  10, 176],\n",
      "          [  3,   1,  95,  ..., 231,   2, 105],\n",
      "          [  0,  86,   0,  ..., 183,   0,  32]]]], dtype=torch.uint8)\n",
      "<class 'torch.Tensor'>\n",
      "<class 'brevitas.quant_tensor.QuantTensor'>\n",
      "difference:: tensor(0.0156, grad_fn=<MaxBackward1>)\n",
      "rms:: tensor(0.0018, grad_fn=<SqrtBackward0>)\n",
      "_________POST PTQ SCALES_________\n",
      "init_scale: tensor(0.0078)\n",
      "block_0_relu1: tensor(0.0039)\n",
      "block_0_relu2: tensor(0.0039)\n",
      "block_0_relu3: tensor(0.0039)\n",
      "block_0_weight_scale1: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "block_0_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_0_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "block_0_weight_scale_skip: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "block_1_quant_add_1: tensor(0.0039)\n",
      "block_1_relu1: tensor(0.0039)\n",
      "block_1_relu2: tensor(0.0039)\n",
      "block_1_relu3: tensor(0.0039)\n",
      "block_1_weight_scale1: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_1_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_1_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "block_2_quant_add_1: tensor(0.0039)\n",
      "block_2_relu1: tensor(0.0039)\n",
      "block_2_relu2: tensor(0.0039)\n",
      "block_2_relu3: tensor(0.0039)\n",
      "block_2_weight_scale1: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_2_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_2_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "block_3_quant_add_1: tensor(0.0039)\n",
      "block_3_relu1: tensor(0.0039)\n",
      "block_3_relu2: tensor(0.0039)\n",
      "block_3_relu3: tensor(0.0039)\n",
      "block_3_weight_scale1: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_3_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_3_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "combined_scale block0 after first conv1x1: 9.0\n",
      "combined_scale block0 after second conv3x3: 11.0\n",
      "combined_scale block0 after third conv1x1: 11.0\n",
      "combined_scale block0 after adding skip connection: -1.0\n",
      "combined_scale block0 after skip conv1x1: 10.0\n",
      "--------------------------------------------------------------\n",
      "combined_scale block1 after first conv1x1: 11.0\n",
      "combined_scale block1 after second conv3x3: 11.0\n",
      "combined_scale block1 after third conv1x1: 10.0\n",
      "combined_scale block1 after adding skip connection: -0.0\n",
      "--------------------------------------------------------------\n",
      "combined_scale block2 after first conv1x1: 11.0\n",
      "combined_scale block2 after second conv3x3: 11.0\n",
      "combined_scale block2 after third conv1x1: 10.0\n",
      "combined_scale block2 after adding skip connection: -0.0\n",
      "--------------------------------------------------------------\n",
      "combined_scale block3 after first conv1x1: 11.0\n",
      "combined_scale block3 after second conv3x3: 11.0\n",
      "combined_scale block3 after third conv1x1: 10.0\n",
      "combined_scale block3 after adding skip connection: -0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_24072\\3583113412.py:317: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:367.)\n",
      "  print(\"difference::\",torch.max(torch.abs(ofm_mem_fmt*block_3_relu_3 - q_bottleneck_out)))\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_24072\\3583113412.py:328: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:367.)\n",
      "  sq_abs = torch.square(torch.abs(ofm_mem_fmt*block_3_relu_3 - q_bottleneck_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden::Brevitas:: [[[[ 76  94   2 ...  16   3   9]\n",
      "   [ 34  96  73 ...  21  15 167]\n",
      "   [ 19  20  99 ...   8  20  11]\n",
      "   ...\n",
      "   [ 22   5   7 ...   7  17 176]\n",
      "   [ 98   1  13 ...   5 127   8]\n",
      "   [ 16   6  19 ...  66  17   8]]\n",
      "\n",
      "  [[ 85  90 121 ...  27  76   5]\n",
      "   [  3 125   5 ...   0   9   0]\n",
      "   [ 26  13 179 ...   3   0  24]\n",
      "   ...\n",
      "   [  8   9  16 ...   0  98   3]\n",
      "   [170  37 108 ...  93  69   3]\n",
      "   [ 22   7   0 ...   9  83 101]]\n",
      "\n",
      "  [[  7  99   0 ... 110  12  77]\n",
      "   [158   0  99 ...  71  23   0]\n",
      "   [ 91   4  18 ...   8  87  48]\n",
      "   ...\n",
      "   [  3  52  49 ...  69   0   0]\n",
      "   [  0   6 107 ...   0   0   8]\n",
      "   [  0 125 248 ...   0  71 181]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 20  23   6 ...   8   6   9]\n",
      "   [218   3  96 ...   7 247  59]\n",
      "   [ 45   5  11 ...  10   5 250]\n",
      "   ...\n",
      "   [ 62   8   2 ...  71   6  24]\n",
      "   [ 13 197  43 ...   2  18   0]\n",
      "   [  0   0  86 ...   3 122  74]]\n",
      "\n",
      "  [[ 99  10 132 ...   5  16   2]\n",
      "   [ 11  23   4 ...  10  26   4]\n",
      "   [  6   8  18 ...   0   0   2]\n",
      "   ...\n",
      "   [ 10  87   8 ...   0  13  10]\n",
      "   [  3   3  51 ... 119  11  48]\n",
      "   [ 14  14   8 ...  80  13   8]]\n",
      "\n",
      "  [[  0   5   4 ...  81   5 227]\n",
      "   [  0   9   6 ... 254  28   0]\n",
      "   [  1  85  14 ...  14  62  21]\n",
      "   ...\n",
      "   [  4  72 126 ...   6  62  49]\n",
      "   [  5  65 139 ... 102   1  17]\n",
      "   [  2   2 108 ...  86   3   0]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gagan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\brevitas\\export\\onnx\\standard\\manager.py:26: UserWarning: ONNX opset version set to 13, override with opset_version=\n",
      "  warnings.warn(f\"ONNX opset version set to {DEFAULT_OPSET}, override with {ka}=\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "total_wts (143360,)\n",
      "AIE output::: tensor([[[[ 76,  94,   2,  ...,  16,   3,   9],\n",
      "          [ 35,  96,  73,  ...,  21,  15, 167],\n",
      "          [ 18,  19,  99,  ...,   8,  21,  11],\n",
      "          ...,\n",
      "          [ 22,   5,   7,  ...,   7,  16, 177],\n",
      "          [ 98,   1,  13,  ...,   4, 127,   8],\n",
      "          [ 15,   6,  18,  ...,  66,  16,   8]],\n",
      "\n",
      "         [[ 85,  90, 121,  ...,  27,  76,   4],\n",
      "          [  3, 125,   5,  ...,   0,   8,   0],\n",
      "          [ 26,  13, 179,  ...,   3,   0,  23],\n",
      "          ...,\n",
      "          [  8,   9,  16,  ...,   0,  98,   2],\n",
      "          [172,  37, 108,  ...,  92,  69,   4],\n",
      "          [ 22,   6,   0,  ...,   9,  82, 101]],\n",
      "\n",
      "         [[  7,  99,   0,  ..., 110,  12,  77],\n",
      "          [158,   0,  99,  ...,  71,  24,   0],\n",
      "          [ 91,   4,  18,  ...,   8,  87,  48],\n",
      "          ...,\n",
      "          [  4,  51,  49,  ...,  69,   0,   0],\n",
      "          [  0,   5, 106,  ...,   0,   0,   8],\n",
      "          [  0, 125, 248,  ...,   0,  70, 181]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 20,  23,   6,  ...,   8,   6,   9],\n",
      "          [217,   3,  96,  ...,   7, 247,  59],\n",
      "          [ 45,   5,  11,  ...,  10,   5, 251],\n",
      "          ...,\n",
      "          [ 62,   8,   2,  ...,  71,   6,  24],\n",
      "          [ 13, 197,  43,  ...,   3,  18,   0],\n",
      "          [  0,   0,  85,  ...,   3, 123,  74]],\n",
      "\n",
      "         [[ 99,  10, 132,  ...,   5,  15,   2],\n",
      "          [ 12,  23,   4,  ...,  10,  26,   4],\n",
      "          [  6,   8,  18,  ...,   0,   0,   2],\n",
      "          ...,\n",
      "          [ 10,  87,   8,  ...,   0,  13,   9],\n",
      "          [  4,   4,  52,  ..., 120,  10,  47],\n",
      "          [ 14,  14,   8,  ...,  80,  12,   8]],\n",
      "\n",
      "         [[  0,   5,   3,  ...,  81,   5, 227],\n",
      "          [  0,   9,   6,  ..., 254,  28,   0],\n",
      "          [  1,  83,  14,  ...,  14,  62,  21],\n",
      "          ...,\n",
      "          [  4,  72, 125,  ...,   6,  62,  50],\n",
      "          [  5,  65, 138,  ..., 102,   1,  18],\n",
      "          [  2,   2, 108,  ...,  86,   3,   0]]]], dtype=torch.uint8)\n",
      "<class 'torch.Tensor'>\n",
      "<class 'brevitas.quant_tensor.QuantTensor'>\n",
      "difference:: tensor(0.0156, grad_fn=<MaxBackward1>)\n",
      "rms:: tensor(0.0017, grad_fn=<SqrtBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_24072\\3583113412.py:317: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:367.)\n",
      "  print(\"difference::\",torch.max(torch.abs(ofm_mem_fmt*block_3_relu_3 - q_bottleneck_out)))\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_24072\\3583113412.py:328: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:367.)\n",
      "  sq_abs = torch.square(torch.abs(ofm_mem_fmt*block_3_relu_3 - q_bottleneck_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________POST PTQ SCALES_________\n",
      "init_scale: tensor(0.0078)\n",
      "block_0_relu1: tensor(0.0039)\n",
      "block_0_relu2: tensor(0.0039)\n",
      "block_0_relu3: tensor(0.0039)\n",
      "block_0_weight_scale1: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "block_0_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_0_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "block_0_weight_scale_skip: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "block_1_quant_add_1: tensor(0.0039)\n",
      "block_1_relu1: tensor(0.0039)\n",
      "block_1_relu2: tensor(0.0039)\n",
      "block_1_relu3: tensor(0.0039)\n",
      "block_1_weight_scale1: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_1_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_1_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "block_2_quant_add_1: tensor(0.0039)\n",
      "block_2_relu1: tensor(0.0039)\n",
      "block_2_relu2: tensor(0.0039)\n",
      "block_2_relu3: tensor(0.0039)\n",
      "block_2_weight_scale1: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_2_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_2_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "block_3_quant_add_1: tensor(0.0039)\n",
      "block_3_relu1: tensor(0.0039)\n",
      "block_3_relu2: tensor(0.0039)\n",
      "block_3_relu3: tensor(0.0039)\n",
      "block_3_weight_scale1: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_3_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_3_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "combined_scale block0 after first conv1x1: 9.0\n",
      "combined_scale block0 after second conv3x3: 11.0\n",
      "combined_scale block0 after third conv1x1: 11.0\n",
      "combined_scale block0 after adding skip connection: -1.0\n",
      "combined_scale block0 after skip conv1x1: 10.0\n",
      "--------------------------------------------------------------\n",
      "combined_scale block1 after first conv1x1: 11.0\n",
      "combined_scale block1 after second conv3x3: 11.0\n",
      "combined_scale block1 after third conv1x1: 10.0\n",
      "combined_scale block1 after adding skip connection: -0.0\n",
      "--------------------------------------------------------------\n",
      "combined_scale block2 after first conv1x1: 11.0\n",
      "combined_scale block2 after second conv3x3: 11.0\n",
      "combined_scale block2 after third conv1x1: 10.0\n",
      "combined_scale block2 after adding skip connection: -0.0\n",
      "--------------------------------------------------------------\n",
      "combined_scale block3 after first conv1x1: 11.0\n",
      "combined_scale block3 after second conv3x3: 11.0\n",
      "combined_scale block3 after third conv1x1: 10.0\n",
      "combined_scale block3 after adding skip connection: -0.0\n",
      "Golden::Brevitas:: [[[[131   0   0 ...   0 197   0]\n",
      "   [ 17   0  36 ...  15 182   0]\n",
      "   [  1  12 192 ... 181  43   0]\n",
      "   ...\n",
      "   [  0 245 143 ...   0  57 115]\n",
      "   [247 136  46 ...   0  25  78]\n",
      "   [  1   4   0 ...   0   4  80]]\n",
      "\n",
      "  [[ 80  98 224 ... 129  10  55]\n",
      "   [  6   8  30 ... 251  15  10]\n",
      "   [ 10  10 255 ...  83  50 111]\n",
      "   ...\n",
      "   [196   8  14 ...   9  15   2]\n",
      "   [ 14   6  20 ...   4   9   0]\n",
      "   [  0  11  68 ...   9  52 197]]\n",
      "\n",
      "  [[  7  95  40 ...  99   2 156]\n",
      "   [ 34  13  80 ... 169   9   3]\n",
      "   [ 12 106   2 ...  14 210   4]\n",
      "   ...\n",
      "   [ 14  10   9 ... 100  13   6]\n",
      "   [115  22  44 ...  13  51   9]\n",
      "   [ 55  11  95 ... 150   7   2]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  1 111 111 ...  37   0   9]\n",
      "   [  0   0   6 ...   3   2  13]\n",
      "   [  0  18   0 ...   3 170  12]\n",
      "   ...\n",
      "   [ 55 171   6 ... 127  11   0]\n",
      "   [137  75   4 ...   3 141   0]\n",
      "   [  1  10   5 ...  43   6   0]]\n",
      "\n",
      "  [[  7   0   0 ...   0   0   0]\n",
      "   [  1 149   1 ...   0   0   0]\n",
      "   [ 77  45   0 ...   7   0  95]\n",
      "   ...\n",
      "   [ 15   0   6 ...   0   0   0]\n",
      "   [  1   0   0 ...   0   1  99]\n",
      "   [  0  49  19 ...   1  26 124]]\n",
      "\n",
      "  [[  3  23  10 ...   0  51  12]\n",
      "   [216 105   6 ...  40  11  17]\n",
      "   [  6 178   9 ...  25  15  47]\n",
      "   ...\n",
      "   [ 17  75  13 ...  16   6  27]\n",
      "   [  0  20  10 ...  12   7  21]\n",
      "   [ 28   3 188 ...  19  10  15]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gagan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\brevitas\\export\\onnx\\standard\\manager.py:26: UserWarning: ONNX opset version set to 13, override with opset_version=\n",
      "  warnings.warn(f\"ONNX opset version set to {DEFAULT_OPSET}, override with {ka}=\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "total_wts (143360,)\n",
      "AIE output::: tensor([[[[131,   0,   0,  ...,   0, 197,   0],\n",
      "          [ 17,   0,  36,  ...,  15, 183,   0],\n",
      "          [  1,  12, 191,  ..., 181,  43,   0],\n",
      "          ...,\n",
      "          [  0, 244, 143,  ...,   0,  57, 115],\n",
      "          [247, 137,  46,  ...,   0,  25,  77],\n",
      "          [  1,   4,   0,  ...,   0,   4,  80]],\n",
      "\n",
      "         [[ 80,  98, 223,  ..., 129,   9,  55],\n",
      "          [  6,   7,  30,  ..., 251,  15,  10],\n",
      "          [ 10,  10, 255,  ...,  83,  50, 111],\n",
      "          ...,\n",
      "          [196,   8,  14,  ...,   9,  15,   2],\n",
      "          [ 15,   6,  20,  ...,   4,   9,   0],\n",
      "          [  0,  11,  68,  ...,   9,  52, 197]],\n",
      "\n",
      "         [[  7,  93,  40,  ...,  99,   2, 156],\n",
      "          [ 34,  13,  80,  ..., 169,   9,   4],\n",
      "          [ 12, 107,   2,  ...,  14, 209,   4],\n",
      "          ...,\n",
      "          [ 14,  11,   9,  ..., 100,  13,   6],\n",
      "          [115,  22,  44,  ...,  13,  51,   9],\n",
      "          [ 55,  11,  96,  ..., 150,   7,   2]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  0, 110, 111,  ...,  37,   0,   9],\n",
      "          [  0,   0,   6,  ...,   5,   2,  14],\n",
      "          [  0,  18,   0,  ...,   4, 170,  13],\n",
      "          ...,\n",
      "          [ 55, 170,   5,  ..., 125,  11,   0],\n",
      "          [137,  75,   4,  ...,   3, 141,   0],\n",
      "          [  1,  10,   6,  ...,  43,   6,   0]],\n",
      "\n",
      "         [[  7,   0,   0,  ...,   0,   0,   0],\n",
      "          [  1, 150,   1,  ...,   0,   0,   0],\n",
      "          [ 77,  45,   0,  ...,   6,   0,  95],\n",
      "          ...,\n",
      "          [ 15,   0,   6,  ...,   0,   0,   0],\n",
      "          [  2,   0,   0,  ...,   0,   1,  99],\n",
      "          [  0,  49,  20,  ...,   1,  26, 124]],\n",
      "\n",
      "         [[  3,  23,  10,  ...,   0,  51,  12],\n",
      "          [216, 105,   6,  ...,  39,  10,  17],\n",
      "          [  6, 178,   9,  ...,  25,  15,  48],\n",
      "          ...,\n",
      "          [ 18,  75,  13,  ...,  17,   6,  27],\n",
      "          [  0,  21,  10,  ...,  12,   7,  21],\n",
      "          [ 28,   3, 188,  ...,  19,  11,  15]]]], dtype=torch.uint8)\n",
      "<class 'torch.Tensor'>\n",
      "<class 'brevitas.quant_tensor.QuantTensor'>\n",
      "difference:: tensor(0.0156, grad_fn=<MaxBackward1>)\n",
      "rms:: tensor(0.0017, grad_fn=<SqrtBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_24072\\3583113412.py:317: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:367.)\n",
      "  print(\"difference::\",torch.max(torch.abs(ofm_mem_fmt*block_3_relu_3 - q_bottleneck_out)))\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_24072\\3583113412.py:328: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:367.)\n",
      "  sq_abs = torch.square(torch.abs(ofm_mem_fmt*block_3_relu_3 - q_bottleneck_out))\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 4):\n",
    "\n",
    "    class QuantBottleneck_projected(nn.Module):\n",
    "        expansion = 4\n",
    "\n",
    "        def __init__(self, in_planes=64, planes=64):\n",
    "            super(QuantBottleneck_projected, self).__init__()\n",
    "            # block 0\n",
    "            self.quant_id_1 = QuantIdentity(\n",
    "                act_quant=Int8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block0_conv1 = QuantConv2d(\n",
    "                in_planes,\n",
    "                planes,\n",
    "                kernel_size=1,\n",
    "                bit_width=8,\n",
    "                weight_bit_width=8,\n",
    "                bias=False,\n",
    "                weight_quant=Int8WeightPerTensorFixedPoint,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block0_conv2 = QuantConv2d(\n",
    "                planes,\n",
    "                planes,\n",
    "                kernel_size=3,\n",
    "                bit_width=8,\n",
    "                weight_bit_width=8,\n",
    "                bias=False,\n",
    "                padding=1,\n",
    "                padding_mode=\"zeros\",\n",
    "                weight_quant=Int8WeightPerTensorFixedPoint,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block0_conv3 = QuantConv2d(\n",
    "                planes,\n",
    "                self.expansion * planes,\n",
    "                kernel_size=1,\n",
    "                bit_width=8,\n",
    "                weight_bit_width=8,\n",
    "                bias=False,\n",
    "                weight_quant=Int8WeightPerTensorFixedPoint,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block0_relu1 = QuantReLU(\n",
    "                act_quant=Uint8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block0_relu2 = QuantReLU(\n",
    "                act_quant=Uint8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block0_relu3 = QuantReLU(\n",
    "                act_quant=Uint8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "\n",
    "            self.shortcut = QuantConv2d(\n",
    "                in_planes,\n",
    "                self.expansion * planes,\n",
    "                kernel_size=1,\n",
    "                bit_width=8,\n",
    "                weight_bit_width=8,\n",
    "                bias=False,\n",
    "                weight_quant=Int8WeightPerTensorFixedPoint,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "\n",
    "            # block 1\n",
    "            self.quant_block1_conv1 = QuantConv2d(\n",
    "                self.expansion * in_planes,\n",
    "                planes,\n",
    "                kernel_size=1,\n",
    "                bit_width=8,\n",
    "                weight_bit_width=8,\n",
    "                bias=False,\n",
    "                weight_quant=Int8WeightPerTensorFixedPoint,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block1_conv2 = QuantConv2d(\n",
    "                planes,\n",
    "                planes,\n",
    "                kernel_size=3,\n",
    "                bit_width=8,\n",
    "                weight_bit_width=8,\n",
    "                bias=False,\n",
    "                padding=1,\n",
    "                padding_mode=\"zeros\",\n",
    "                weight_quant=Int8WeightPerTensorFixedPoint,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block1_conv3 = QuantConv2d(\n",
    "                planes,\n",
    "                self.expansion * planes,\n",
    "                kernel_size=1,\n",
    "                bit_width=8,\n",
    "                weight_bit_width=8,\n",
    "                bias=False,\n",
    "                weight_quant=Int8WeightPerTensorFixedPoint,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block1_relu1 = QuantReLU(\n",
    "                act_quant=Uint8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block1_relu2 = QuantReLU(\n",
    "                act_quant=Uint8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block1_relu3 = QuantReLU(\n",
    "                act_quant=Uint8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "\n",
    "            self.quant_add_1 = QuantIdentity(\n",
    "                act_quant=Int8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            # Quant_add_1 shares the scale factors with block0_relu3, however one is signed and the other one is unsigned\n",
    "            self.quant_add_1.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl = (\n",
    "                self.quant_block0_relu3.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl\n",
    "            )\n",
    "            self.quant_add_1.act_quant.fused_activation_quant_proxy.tensor_quant.int_scaling_impl = (\n",
    "                self.quant_block0_relu3.act_quant.fused_activation_quant_proxy.tensor_quant.int_scaling_impl\n",
    "            )\n",
    "\n",
    "            # block 2\n",
    "            self.quant_block2_conv1 = QuantConv2d(\n",
    "                self.expansion * in_planes,\n",
    "                planes,\n",
    "                kernel_size=1,\n",
    "                bit_width=8,\n",
    "                weight_bit_width=8,\n",
    "                bias=False,\n",
    "                weight_quant=Int8WeightPerTensorFixedPoint,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block2_conv2 = QuantConv2d(\n",
    "                planes,\n",
    "                planes,\n",
    "                kernel_size=3,\n",
    "                bit_width=8,\n",
    "                weight_bit_width=8,\n",
    "                bias=False,\n",
    "                padding=1,\n",
    "                padding_mode=\"zeros\",\n",
    "                weight_quant=Int8WeightPerTensorFixedPoint,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block2_conv3 = QuantConv2d(\n",
    "                planes,\n",
    "                self.expansion * planes,\n",
    "                kernel_size=1,\n",
    "                bit_width=8,\n",
    "                weight_bit_width=8,\n",
    "                bias=False,\n",
    "                weight_quant=Int8WeightPerTensorFixedPoint,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block2_relu1 = QuantReLU(\n",
    "                act_quant=Uint8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block2_relu2 = QuantReLU(\n",
    "                act_quant=Uint8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block2_relu3 = QuantReLU(\n",
    "                act_quant=Uint8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "\n",
    "            self.quant_add_2 = QuantIdentity(\n",
    "                act_quant=Int8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            # Quant_add_1 shares the scale factors with block0_relu3, however one is signed and the other one is unsigned\n",
    "            self.quant_add_2.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl = (\n",
    "                self.quant_block1_relu3.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl\n",
    "            )\n",
    "            self.quant_add_2.act_quant.fused_activation_quant_proxy.tensor_quant.int_scaling_impl = (\n",
    "                self.quant_block1_relu3.act_quant.fused_activation_quant_proxy.tensor_quant.int_scaling_impl\n",
    "            )\n",
    "\n",
    "            # block 3\n",
    "            self.quant_block3_conv1 = QuantConv2d(\n",
    "                self.expansion * in_planes,\n",
    "                planes,\n",
    "                kernel_size=1,\n",
    "                bit_width=8,\n",
    "                weight_bit_width=8,\n",
    "                bias=False,\n",
    "                weight_quant=Int8WeightPerTensorFixedPoint,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block3_conv2 = QuantConv2d(\n",
    "                planes,\n",
    "                planes,\n",
    "                kernel_size=3,\n",
    "                bit_width=8,\n",
    "                weight_bit_width=8,\n",
    "                bias=False,\n",
    "                padding=1,\n",
    "                padding_mode=\"zeros\",\n",
    "                weight_quant=Int8WeightPerTensorFixedPoint,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block3_conv3 = QuantConv2d(\n",
    "                planes,\n",
    "                self.expansion * planes,\n",
    "                kernel_size=1,\n",
    "                bit_width=8,\n",
    "                weight_bit_width=8,\n",
    "                bias=False,\n",
    "                weight_quant=Int8WeightPerTensorFixedPoint,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block3_relu1 = QuantReLU(\n",
    "                act_quant=Uint8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block3_relu2 = QuantReLU(\n",
    "                act_quant=Uint8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block3_relu3 = QuantReLU(\n",
    "                act_quant=Uint8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "\n",
    "            self.quant_add_3 = QuantIdentity(\n",
    "                act_quant=Int8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            # Quant_add_1 shares the scale factors with block0_relu3, however one is signed and the other one is unsigned\n",
    "            self.quant_add_3.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl = (\n",
    "                self.quant_block2_relu3.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl\n",
    "            )\n",
    "            self.quant_add_3.act_quant.fused_activation_quant_proxy.tensor_quant.int_scaling_impl = (\n",
    "                self.quant_block2_relu3.act_quant.fused_activation_quant_proxy.tensor_quant.int_scaling_impl\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            out_q = self.quant_id_1(x)\n",
    "            out_rhs = self.quant_block0_conv1(out_q)\n",
    "            out_rhs = self.quant_block0_relu1(out_rhs)\n",
    "            out_rhs = self.quant_block0_conv2(out_rhs)\n",
    "            out_rhs = self.quant_block0_relu2(out_rhs)\n",
    "            out_rhs = self.quant_block0_conv3(out_rhs)\n",
    "            out_rhs = self.quant_id_1(out_rhs)\n",
    "            out_lhs = self.shortcut(out_q)\n",
    "            out_lhs = self.quant_id_1(out_lhs)\n",
    "            out_block0 = out_rhs + out_lhs\n",
    "            out_block0 = self.quant_block0_relu3(out_block0)\n",
    "            # block 1\n",
    "            out_rhs1 = self.quant_block1_conv1(out_block0)\n",
    "            out_rhs1 = self.quant_block1_relu1(out_rhs1)\n",
    "            out_rhs1 = self.quant_block1_conv2(out_rhs1)\n",
    "            out_rhs1 = self.quant_block1_relu2(out_rhs1)\n",
    "            out_rhs1 = self.quant_block1_conv3(out_rhs1)\n",
    "            out_rhs1 = self.quant_add_1(out_rhs1)\n",
    "            out_block1 = out_block0 + out_rhs1\n",
    "            # out_block1=out_block0\n",
    "            out_block1 = self.quant_block1_relu3(out_block1)\n",
    "\n",
    "            # block 2\n",
    "            out_rhs2 = self.quant_block2_conv1(out_block1)\n",
    "            out_rhs2 = self.quant_block2_relu1(out_rhs2)\n",
    "            out_rhs2 = self.quant_block2_conv2(out_rhs2)\n",
    "            out_rhs2 = self.quant_block2_relu2(out_rhs2)\n",
    "            out_rhs2 = self.quant_block2_conv3(out_rhs2)\n",
    "            out_rhs2 = self.quant_add_2(out_rhs2)\n",
    "            out_block2 = out_block1 + out_rhs2\n",
    "            # out_block1=out_block0\n",
    "            out_block2 = self.quant_block2_relu3(out_block2)\n",
    "\n",
    "            # block 3\n",
    "            out_rhs3 = self.quant_block3_conv1(out_block2)\n",
    "            out_rhs3 = self.quant_block3_relu1(out_rhs3)\n",
    "            out_rhs3 = self.quant_block3_conv2(out_rhs3)\n",
    "            out_rhs3 = self.quant_block3_relu2(out_rhs3)\n",
    "            out_rhs3 = self.quant_block3_conv3(out_rhs3)\n",
    "            out_rhs3 = self.quant_add_3(out_rhs3)\n",
    "            out_block3 = out_block2 + out_rhs3\n",
    "            # out_block1=out_block0\n",
    "            out_block3 = self.quant_block3_relu3(out_block3)\n",
    "\n",
    "            return out_block3\n",
    "\n",
    "    input = torch.randn(1, 64, 32, 32)\n",
    "    quant_bottleneck_model = QuantBottleneck_projected()\n",
    "\n",
    "    quant_id_1 = QuantIdentity(\n",
    "        act_quant=Int8ActPerTensorFixedPoint, bit_width=8, return_quant_tensor=True\n",
    "    )\n",
    "    quant_bottleneck_model.eval()\n",
    "    quant_id_1.eval()\n",
    "    # from brevitas_examples.imagenet_classification.ptq.ptq_common import calibrate\n",
    "    # calibrate([(torch.rand(32,64,32,32), 1) for _ in range(5)], quant_bottleneck_model)\n",
    "    # #\n",
    "    # from brevitas.fx import brevitas_symbolic_trace\n",
    "    # model = brevitas_symbolic_trace(quant_bottleneck_model)\n",
    "    # print(model.graph)\n",
    "\n",
    "    init_scale = quant_bottleneck_model.quant_id_1.quant_act_scale()\n",
    "    block_0_relu_1 = quant_bottleneck_model.quant_block0_relu1.quant_act_scale()\n",
    "    block_0_relu_2 = quant_bottleneck_model.quant_block0_relu2.quant_act_scale()\n",
    "    block_0_relu_3 = quant_bottleneck_model.quant_block0_relu3.quant_act_scale()\n",
    "\n",
    "    block_0_weight_scale1 = (\n",
    "        quant_bottleneck_model.quant_block0_conv1.quant_weight_scale()\n",
    "    )\n",
    "    block_0_weight_scale2 = (\n",
    "        quant_bottleneck_model.quant_block0_conv2.quant_weight_scale()\n",
    "    )\n",
    "    block_0_weight_scale3 = (\n",
    "        quant_bottleneck_model.quant_block0_conv3.quant_weight_scale()\n",
    "    )\n",
    "    block_0_weight_scale_skip = quant_bottleneck_model.shortcut.quant_weight_scale()\n",
    "\n",
    "    # Block 1\n",
    "    block_1_relu_1 = quant_bottleneck_model.quant_block1_relu1.quant_act_scale()\n",
    "    block_1_relu_2 = quant_bottleneck_model.quant_block1_relu2.quant_act_scale()\n",
    "    block_1_relu_3 = quant_bottleneck_model.quant_block1_relu3.quant_act_scale()\n",
    "\n",
    "    block_1_weight_scale1 = (\n",
    "        quant_bottleneck_model.quant_block1_conv1.quant_weight_scale()\n",
    "    )\n",
    "    block_1_weight_scale2 = (\n",
    "        quant_bottleneck_model.quant_block1_conv2.quant_weight_scale()\n",
    "    )\n",
    "    block_1_weight_scale3 = (\n",
    "        quant_bottleneck_model.quant_block1_conv3.quant_weight_scale()\n",
    "    )\n",
    "    block_1_quant_add_1 = quant_bottleneck_model.quant_add_1.quant_act_scale()\n",
    "\n",
    "    # Block 2\n",
    "    block_2_relu_1 = quant_bottleneck_model.quant_block2_relu1.quant_act_scale()\n",
    "    block_2_relu_2 = quant_bottleneck_model.quant_block2_relu2.quant_act_scale()\n",
    "    block_2_relu_3 = quant_bottleneck_model.quant_block2_relu3.quant_act_scale()\n",
    "\n",
    "    block_2_weight_scale1 = (\n",
    "        quant_bottleneck_model.quant_block2_conv1.quant_weight_scale()\n",
    "    )\n",
    "    block_2_weight_scale2 = (\n",
    "        quant_bottleneck_model.quant_block2_conv2.quant_weight_scale()\n",
    "    )\n",
    "    block_2_weight_scale3 = (\n",
    "        quant_bottleneck_model.quant_block2_conv3.quant_weight_scale()\n",
    "    )\n",
    "    block_2_quant_add_1 = quant_bottleneck_model.quant_add_2.quant_act_scale()\n",
    "\n",
    "    # Block 3\n",
    "    block_3_relu_1 = quant_bottleneck_model.quant_block3_relu1.quant_act_scale()\n",
    "    block_3_relu_2 = quant_bottleneck_model.quant_block3_relu2.quant_act_scale()\n",
    "    block_3_relu_3 = quant_bottleneck_model.quant_block3_relu3.quant_act_scale()\n",
    "\n",
    "    block_3_weight_scale1 = (\n",
    "        quant_bottleneck_model.quant_block3_conv1.quant_weight_scale()\n",
    "    )\n",
    "    block_3_weight_scale2 = (\n",
    "        quant_bottleneck_model.quant_block3_conv2.quant_weight_scale()\n",
    "    )\n",
    "    block_3_weight_scale3 = (\n",
    "        quant_bottleneck_model.quant_block3_conv3.quant_weight_scale()\n",
    "    )\n",
    "    block_3_quant_add_1 = quant_bottleneck_model.quant_add_3.quant_act_scale()\n",
    "\n",
    "    block_0_int_weight_1 = quant_bottleneck_model.quant_block0_conv1.quant_weight().int(\n",
    "        float_datatype=True\n",
    "    )\n",
    "    block_0_int_weight_2 = quant_bottleneck_model.quant_block0_conv2.quant_weight().int(\n",
    "        float_datatype=True\n",
    "    )\n",
    "    block_0_int_weight_3 = quant_bottleneck_model.quant_block0_conv3.quant_weight().int(\n",
    "        float_datatype=True\n",
    "    )\n",
    "    block_0_int_weight_skip = quant_bottleneck_model.shortcut.quant_weight().int(\n",
    "        float_datatype=True\n",
    "    )\n",
    "\n",
    "    block_1_int_weight_1 = quant_bottleneck_model.quant_block1_conv1.quant_weight().int(\n",
    "        float_datatype=True\n",
    "    )\n",
    "    block_1_int_weight_2 = quant_bottleneck_model.quant_block1_conv2.quant_weight().int(\n",
    "        float_datatype=True\n",
    "    )\n",
    "    block_1_int_weight_3 = quant_bottleneck_model.quant_block1_conv3.quant_weight().int(\n",
    "        float_datatype=True\n",
    "    )\n",
    "\n",
    "    block_2_int_weight_1 = quant_bottleneck_model.quant_block2_conv1.quant_weight().int(\n",
    "        float_datatype=True\n",
    "    )\n",
    "    block_2_int_weight_2 = quant_bottleneck_model.quant_block2_conv2.quant_weight().int(\n",
    "        float_datatype=True\n",
    "    )\n",
    "    block_2_int_weight_3 = quant_bottleneck_model.quant_block2_conv3.quant_weight().int(\n",
    "        float_datatype=True\n",
    "    )\n",
    "\n",
    "    block_3_int_weight_1 = quant_bottleneck_model.quant_block3_conv1.quant_weight().int(\n",
    "        float_datatype=True\n",
    "    )\n",
    "    block_3_int_weight_2 = quant_bottleneck_model.quant_block3_conv2.quant_weight().int(\n",
    "        float_datatype=True\n",
    "    )\n",
    "    block_3_int_weight_3 = quant_bottleneck_model.quant_block3_conv3.quant_weight().int(\n",
    "        float_datatype=True\n",
    "    )\n",
    "\n",
    "    block_0_combined_scale1 = -torch.log2(\n",
    "        init_scale * block_0_weight_scale1 / block_0_relu_1\n",
    "    )  # RHS after first conv1x1 | clip 0-->255\n",
    "    block_0_combined_scale2 = -torch.log2(\n",
    "        block_0_relu_1 * block_0_weight_scale2 / block_0_relu_2\n",
    "    )  # RHS after second conv3x3 | clip 0-->255\n",
    "    block_0_combined_scale3 = -torch.log2(\n",
    "        block_0_relu_2 * block_0_weight_scale3 / init_scale\n",
    "    )  # RHS after third conv1x1 | clip -128-->+127\n",
    "    block_0_combined_scale_skip = -torch.log2(\n",
    "        init_scale * block_0_weight_scale_skip / init_scale\n",
    "    )  # LHS after conv1x1 | clip -128-->+127\n",
    "    block_0_combined_scale4 = -torch.log2(\n",
    "        init_scale / block_0_relu_3\n",
    "    )  # After addition | clip 0-->255\n",
    "\n",
    "    block_1_combined_scale1 = -torch.log2(\n",
    "        block_0_relu_3 * block_1_weight_scale1 / block_1_relu_1\n",
    "    )  # RHS after first conv1x1 | clip 0-->255\n",
    "    block_1_combined_scale2 = -torch.log2(\n",
    "        block_1_relu_1 * block_1_weight_scale2 / block_1_relu_2\n",
    "    )  # RHS after second conv3x3 | clip 0-->255\n",
    "    block_1_combined_scale3 = -torch.log2(\n",
    "        block_1_relu_2 * block_1_weight_scale3 / block_1_quant_add_1\n",
    "    )  # RHS after third conv1x1 | clip -128-->+127\n",
    "    block_1_combined_scale4 = -torch.log2(\n",
    "        block_1_quant_add_1 / block_1_relu_3\n",
    "    )  # After addition | clip 0-->255\n",
    "\n",
    "    block_2_combined_scale1 = -torch.log2(\n",
    "        block_1_relu_3 * block_2_weight_scale1 / block_2_relu_1\n",
    "    )  # RHS after first conv1x1 | clip 0-->255\n",
    "    block_2_combined_scale2 = -torch.log2(\n",
    "        block_2_relu_1 * block_2_weight_scale2 / block_2_relu_2\n",
    "    )  # RHS after second conv3x3 | clip 0-->255\n",
    "    block_2_combined_scale3 = -torch.log2(\n",
    "        block_2_relu_2 * block_2_weight_scale3 / block_2_quant_add_1\n",
    "    )  # RHS after third conv1x1 | clip -128-->+127\n",
    "    block_2_combined_scale4 = -torch.log2(\n",
    "        block_2_quant_add_1 / block_2_relu_3\n",
    "    )  # After addition | clip 0-->255\n",
    "\n",
    "    block_3_combined_scale1 = -torch.log2(\n",
    "        block_2_relu_3 * block_3_weight_scale1 / block_3_relu_1\n",
    "    )  # RHS after first conv1x1 | clip 0-->255\n",
    "    block_3_combined_scale2 = -torch.log2(\n",
    "        block_3_relu_1 * block_3_weight_scale2 / block_3_relu_2\n",
    "    )  # RHS after second conv3x3 | clip 0-->255\n",
    "    block_3_combined_scale3 = -torch.log2(\n",
    "        block_3_relu_2 * block_3_weight_scale3 / block_3_quant_add_1\n",
    "    )  # RHS after third conv1x1 | clip -128-->+127\n",
    "    block_3_combined_scale4 = -torch.log2(\n",
    "        block_3_quant_add_1 / block_3_relu_3\n",
    "    )  # After addition | clip 0-->255\n",
    "\n",
    "    print(\"_________POST PTQ SCALES_________\")\n",
    "    print(\"init_scale:\", init_scale)\n",
    "    print(\"block_0_relu1:\", block_0_relu_1)\n",
    "    print(\"block_0_relu2:\", block_0_relu_2)\n",
    "    print(\"block_0_relu3:\", block_0_relu_3)\n",
    "\n",
    "    print(\"block_0_weight_scale1:\", block_0_weight_scale1)\n",
    "    print(\"block_0_weight_scale2:\", block_0_weight_scale2)\n",
    "    print(\"block_0_weight_scale3:\", block_0_weight_scale3)\n",
    "    print(\"block_0_weight_scale_skip:\", block_0_weight_scale_skip)\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "    print(\"block_1_quant_add_1:\", block_1_quant_add_1)\n",
    "    print(\"block_1_relu1:\", block_1_relu_1)\n",
    "    print(\"block_1_relu2:\", block_1_relu_2)\n",
    "    print(\"block_1_relu3:\", block_1_relu_3)\n",
    "    print(\"block_1_weight_scale1:\", block_1_weight_scale1)\n",
    "    print(\"block_1_weight_scale2:\", block_1_weight_scale2)\n",
    "    print(\"block_1_weight_scale3:\", block_1_weight_scale3)\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "    print(\"block_2_quant_add_1:\", block_2_quant_add_1)\n",
    "    print(\"block_2_relu1:\", block_2_relu_1)\n",
    "    print(\"block_2_relu2:\", block_2_relu_2)\n",
    "    print(\"block_2_relu3:\", block_2_relu_3)\n",
    "    print(\"block_2_weight_scale1:\", block_2_weight_scale1)\n",
    "    print(\"block_2_weight_scale2:\", block_2_weight_scale2)\n",
    "    print(\"block_2_weight_scale3:\", block_2_weight_scale3)\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "    print(\"block_3_quant_add_1:\", block_3_quant_add_1)\n",
    "    print(\"block_3_relu1:\", block_3_relu_1)\n",
    "    print(\"block_3_relu2:\", block_3_relu_2)\n",
    "    print(\"block_3_relu3:\", block_3_relu_3)\n",
    "    print(\"block_3_weight_scale1:\", block_3_weight_scale1)\n",
    "    print(\"block_3_weight_scale2:\", block_3_weight_scale2)\n",
    "    print(\"block_3_weight_scale3:\", block_3_weight_scale3)\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "    print(\"combined_scale block0 after first conv1x1:\", block_0_combined_scale1.item())\n",
    "    print(\"combined_scale block0 after second conv3x3:\", block_0_combined_scale2.item())\n",
    "    print(\"combined_scale block0 after third conv1x1:\", block_0_combined_scale3.item())\n",
    "    print(\n",
    "        \"combined_scale block0 after adding skip connection:\",\n",
    "        (block_0_combined_scale4).item(),\n",
    "    )\n",
    "    print(\n",
    "        \"combined_scale block0 after skip conv1x1:\", block_0_combined_scale_skip.item()\n",
    "    )\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "    print(\"combined_scale block1 after first conv1x1:\", block_1_combined_scale1.item())\n",
    "    print(\"combined_scale block1 after second conv3x3:\", block_1_combined_scale2.item())\n",
    "    print(\"combined_scale block1 after third conv1x1:\", block_1_combined_scale3.item())\n",
    "    print(\n",
    "        \"combined_scale block1 after adding skip connection:\",\n",
    "        (block_1_combined_scale4).item(),\n",
    "    )\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "    print(\"combined_scale block2 after first conv1x1:\", block_2_combined_scale1.item())\n",
    "    print(\"combined_scale block2 after second conv3x3:\", block_2_combined_scale2.item())\n",
    "    print(\"combined_scale block2 after third conv1x1:\", block_2_combined_scale3.item())\n",
    "    print(\n",
    "        \"combined_scale block2 after adding skip connection:\",\n",
    "        (block_2_combined_scale4).item(),\n",
    "    )\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "    print(\"combined_scale block3 after first conv1x1:\", block_3_combined_scale1.item())\n",
    "    print(\"combined_scale block3 after second conv3x3:\", block_3_combined_scale2.item())\n",
    "    print(\"combined_scale block3 after third conv1x1:\", block_3_combined_scale3.item())\n",
    "    print(\n",
    "        \"combined_scale block3 after adding skip connection:\",\n",
    "        (block_3_combined_scale4).item(),\n",
    "    )\n",
    "\n",
    "    q_bottleneck_out = quant_bottleneck_model(input)\n",
    "    gold_out = q_bottleneck_out.int(float_datatype=True).data.numpy().astype(dtype_out)\n",
    "    print(\"Golden::Brevitas::\", gold_out)\n",
    "    gold_out.tofile(log_folder + \"/gold_out.txt\", sep=\",\", format=\"%d\")\n",
    "\n",
    "    from brevitas.export import export_onnx_qcdq\n",
    "\n",
    "    # ref_input = torch.ones(1, 3, 32, 32, device=\"cpu\", dtype=dtype)\n",
    "    export_onnx_qcdq(quant_bottleneck_model, input, log_folder + \"/\" + design + \".onnx\")\n",
    "    # # Brevitas convolution\n",
    "    q_inp = quant_id_1(input)\n",
    "    int_inp = q_inp.int(float_datatype=True)\n",
    "\n",
    "    before_input = int_inp.squeeze().data.numpy().astype(dtype_in)\n",
    "\n",
    "    before_input.tofile(\n",
    "        log_folder + \"/before_ifm_mem_fmt_1x1.txt\", sep=\",\", format=\"%d\"\n",
    "    )\n",
    "    ifm_mem_fmt = ds.reorder_mat(before_input, \"YCXC8\", \"CYX\")\n",
    "    ifm_mem_fmt.tofile(log_folder + \"/after_ifm_mem_fmt_1x1.txt\", sep=\",\", format=\"%d\")\n",
    "    block0_wts1 = ds.reorder_mat(\n",
    "        block_0_int_weight_1.data.numpy().astype(dtype_wts), \"OIYXI8O8\", \"OIYX\"\n",
    "    )\n",
    "    block0_wts2 = ds.reorder_mat(\n",
    "        block_0_int_weight_2.data.numpy().astype(dtype_wts), \"OIYXI8O8\", \"OIYX\"\n",
    "    )\n",
    "    block0_wts3 = ds.reorder_mat(\n",
    "        block_0_int_weight_3.data.numpy().astype(dtype_wts), \"OIYXI8O8\", \"OIYX\"\n",
    "    )\n",
    "    block0_wts_skip = ds.reorder_mat(\n",
    "        block_0_int_weight_skip.data.numpy().astype(dtype_wts), \"OIYXI8O8\", \"OIYX\"\n",
    "    )\n",
    "\n",
    "    total_wts = np.concatenate(\n",
    "        (block0_wts1, block0_wts2, block0_wts3, block0_wts_skip), axis=None\n",
    "    )\n",
    "\n",
    "    block1_wts1 = ds.reorder_mat(\n",
    "        block_1_int_weight_1.data.numpy().astype(dtype_wts), \"OIYXI8O8\", \"OIYX\"\n",
    "    )\n",
    "    block1_wts2 = ds.reorder_mat(\n",
    "        block_1_int_weight_2.data.numpy().astype(dtype_wts), \"OIYXI8O8\", \"OIYX\"\n",
    "    )\n",
    "    block1_wts3 = ds.reorder_mat(\n",
    "        block_1_int_weight_3.data.numpy().astype(dtype_wts), \"OIYXI8O8\", \"OIYX\"\n",
    "    )\n",
    "\n",
    "    total_wts2 = np.concatenate(\n",
    "        (total_wts, block1_wts1, block1_wts2, block1_wts3), axis=None\n",
    "    )\n",
    "\n",
    "    block2_wts1 = ds.reorder_mat(\n",
    "        block_2_int_weight_1.data.numpy().astype(dtype_wts), \"OIYXI8O8\", \"OIYX\"\n",
    "    )\n",
    "    block2_wts2 = ds.reorder_mat(\n",
    "        block_2_int_weight_2.data.numpy().astype(dtype_wts), \"OIYXI8O8\", \"OIYX\"\n",
    "    )\n",
    "    block2_wts3 = ds.reorder_mat(\n",
    "        block_2_int_weight_3.data.numpy().astype(dtype_wts), \"OIYXI8O8\", \"OIYX\"\n",
    "    )\n",
    "\n",
    "    total_wts3 = np.concatenate(\n",
    "        (total_wts2, block2_wts1, block2_wts2, block2_wts3), axis=None\n",
    "    )\n",
    "\n",
    "    block3_wts1 = ds.reorder_mat(\n",
    "        block_3_int_weight_1.data.numpy().astype(dtype_wts), \"OIYXI8O8\", \"OIYX\"\n",
    "    )\n",
    "    block3_wts2 = ds.reorder_mat(\n",
    "        block_3_int_weight_2.data.numpy().astype(dtype_wts), \"OIYXI8O8\", \"OIYX\"\n",
    "    )\n",
    "    block3_wts3 = ds.reorder_mat(\n",
    "        block_3_int_weight_3.data.numpy().astype(dtype_wts), \"OIYXI8O8\", \"OIYX\"\n",
    "    )\n",
    "\n",
    "    total_wts4 = np.concatenate(\n",
    "        (total_wts3, block3_wts1, block3_wts2, block3_wts3), axis=None\n",
    "    )\n",
    "\n",
    "    total_wts4.tofile(log_folder + \"/weights_mem_fmt_final.txt\", sep=\",\", format=\"%d\")\n",
    "    print(\"total_wts\", total_wts2.shape)\n",
    "    # for i in range (0,1):\n",
    "    app.buffers[2].write(ifm_mem_fmt)  # input's standard format CYX | scalar YCX\n",
    "    app.buffers[3].write(total_wts4)  # wts's standard format OIYX | scalar OIYX\n",
    "    # app.buffers[3].write(int_weight2.data.numpy().astype(dtype_in),offset=2048) # wts's standard format OIYX | scalar OIYX\n",
    "    app.run()\n",
    "    output3 = app.buffers[4].read()\n",
    "    if enable_trace:\n",
    "        output3, trace = extract_trace(output3, shape_out, dtype_out)\n",
    "        write_out_trace(trace, trace_file)\n",
    "    # temp_out=output3.reshape(32,256, 32)\n",
    "    # ofm_mem_fmt = temp_out.swapaxes(0,1)\n",
    "    temp_out = output3.reshape(32, 32, 32, 8)\n",
    "    temp2_out = ds.reorder_mat(temp_out, \"CDYX\", \"YCXD\")\n",
    "    ofm_mem_fmt = temp2_out.reshape(256, 32, 32)\n",
    "    ofm_mem_fmt.tofile(\n",
    "        log_folder + \"/after_ofm_mem_fmt_final.txt\", sep=\",\", format=\"%d\"\n",
    "    )\n",
    "\n",
    "    ofm_mem_fmt = torch.from_numpy(ofm_mem_fmt).unsqueeze(0)\n",
    "    print(\"AIE output:::\", ofm_mem_fmt)\n",
    "    print(type(ofm_mem_fmt))\n",
    "    print(type(q_bottleneck_out))\n",
    "    print(\n",
    "        \"difference::\",\n",
    "        torch.max(torch.abs(ofm_mem_fmt * block_3_relu_3 - q_bottleneck_out)),\n",
    "    )\n",
    "    diff = torch.abs(ofm_mem_fmt - gold_out)\n",
    "    # print(\"diff::\",diff)\n",
    "    # for i, x1 in enumerate(diff):\n",
    "    #     for j, x2 in enumerate(x1):\n",
    "    #         for k, x3 in enumerate(x2):\n",
    "    #             for l, x4 in enumerate(x3):\n",
    "    #                 if x4 > 3:\n",
    "    #                     print(\"i:\",i,\", j:\",j,\", k:\", k, \", l:\", l, \", val:\",x4)\n",
    "    #                     print(\"ofm_mem_fmt val:\",ofm_mem_fmt[i,j,k,l])\n",
    "    #                     print(\"gold_out val:\",gold_out[i,j,k,l])\n",
    "    sq_abs = torch.square(torch.abs(ofm_mem_fmt * block_3_relu_3 - q_bottleneck_out))\n",
    "    print(\"rms::\", torch.sqrt(torch.sum(sq_abs) / torch.numel(sq_abs)))\n",
    "    assert np.allclose(ofm_mem_fmt, gold_out, rtol=0, atol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5c9e7e-997d-4e29-87e9-6dc4f69113a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_trace:\n",
    "    print(trace)\n",
    "else:\n",
    "    print(\"tracing not enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31861e3-73d3-4197-b802-195c1573eedd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b36a4b-b6b2-4c32-9292-8a0994df8434",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
