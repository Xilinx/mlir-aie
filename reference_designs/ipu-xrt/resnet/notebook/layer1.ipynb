{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eefc1d8-b573-45f1-8d18-f25a0a4ec980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../misc\")\n",
    "from utils import DataShaper\n",
    "import os\n",
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from brevitas.nn import QuantConv2d, QuantIdentity, QuantReLU\n",
    "from brevitas.quant.fixed_point import (\n",
    "    Int8ActPerTensorFixedPoint,\n",
    "    Int8WeightPerTensorFixedPoint,\n",
    "    Uint8ActPerTensorFixedPoint,\n",
    ")\n",
    "\n",
    "ds = DataShaper()\n",
    "torch.manual_seed(0)\n",
    "design = \"layer_1\"\n",
    "# aie_teardown()\n",
    "sys.path.append(\"../../../utils\")\n",
    "import xrtutils\n",
    "\n",
    "xclbin_path = os.path.abspath(\"../network/\" + design + \"/build/final.xclbin\")\n",
    "insts_path = os.path.abspath(\"../network/\" + design + \"/build/insts.txt\")\n",
    "\n",
    "log_folder = \"log/log_\" + design\n",
    "if not os.path.exists(log_folder):\n",
    "    os.makedirs(log_folder)\n",
    "enable_aie = True\n",
    "aie_is_setup = False\n",
    "enable_trace = True\n",
    "trace_file = \"traces/trace.txt\"\n",
    "\n",
    "app = None\n",
    "in_buf = None\n",
    "arg1_buf = None\n",
    "out_buf = None\n",
    "dtype_in = np.dtype(\"int8\")\n",
    "dtype_wts = np.dtype(\"int8\")\n",
    "dtype_out = np.dtype(\"uint8\")\n",
    "\n",
    "shape_in_act = (32, 8, 32, 8)  #'YCXC8' , 'CYX'\n",
    "# shape_in_wts1  = (8,8,1,1,8,8) #out,in,ky,kx,in8,out8\n",
    "# shape_in_wts2  = (8,8,3,3,8,8)  #out,in,ky,kx,in8,out8\n",
    "# shape_in_wts3  = (32,8,1,1,8,8)   #out,in,ky,kx,in8,out8\n",
    "# shape_in_wts_skip  = (8,32,1,1,8,8) #out,in,ky,kx,in8,out8\n",
    "shape_total_wts = (212992, 1)\n",
    "shape_out = (32, 32, 32, 8)\n",
    "\n",
    "trace_size = 16384\n",
    "\n",
    "\n",
    "def setup_aie(\n",
    "    xclbin_path,\n",
    "    insts_path,\n",
    "    in_0_shape,\n",
    "    in_0_dtype,\n",
    "    in_1_shape,\n",
    "    in_1_dtype,\n",
    "    out_buf_shape,\n",
    "    out_buf_dtype,\n",
    "    enable_trace=False,\n",
    "    kernel_name=\"MLIR_AIE\",\n",
    "):\n",
    "    app = xrtutils.AIE_Application(xclbin_path, insts_path, kernel_name)\n",
    "    app.register_buffer(2, shape=in_0_shape, dtype=in_0_dtype)\n",
    "    app.register_buffer(3, shape=in_1_shape, dtype=in_1_dtype)\n",
    "    if enable_trace:\n",
    "        out_buf_len_bytes = np.prod(out_buf_shape) * np.dtype(out_buf_dtype).itemsize\n",
    "        out_buf_shape = (out_buf_len_bytes + trace_size,)\n",
    "        out_buf_dtype = np.uint8\n",
    "    app.register_buffer(4, shape=out_buf_shape, dtype=out_buf_dtype)\n",
    "    return app\n",
    "\n",
    "\n",
    "def extract_trace(out_buf, out_buf_shape, out_buf_dtype):\n",
    "    trace_size_words = trace_size // 4\n",
    "    out_buf_flat = out_buf.reshape((-1,)).view(np.uint32)\n",
    "    output_prefix = (\n",
    "        out_buf_flat[:-trace_size_words].view(out_buf_dtype).reshape(out_buf_shape)\n",
    "    )\n",
    "    trace_suffix = out_buf_flat[-trace_size_words:]\n",
    "    return output_prefix, trace_suffix\n",
    "\n",
    "\n",
    "def write_out_trace(trace, file_name):\n",
    "    out_str = \"\\n\".join(f\"{i:0{8}x}\" for i in trace if i != 0)\n",
    "    with open(file_name, \"w\") as f:\n",
    "        f.write(out_str)\n",
    "\n",
    "\n",
    "app = setup_aie(\n",
    "    xclbin_path,\n",
    "    insts_path,\n",
    "    shape_in_act,\n",
    "    dtype_in,\n",
    "    shape_total_wts,\n",
    "    dtype_wts,\n",
    "    shape_out,\n",
    "    dtype_out,\n",
    "    enable_trace,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a5357e2-a746-42fe-9dda-20d2029d228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "from brevitas.nn import QuantConv2d, QuantIdentity, QuantReLU\n",
    "from brevitas.quant.fixed_point import (\n",
    "    Int8ActPerTensorFixedPoint,\n",
    "    Int8WeightPerTensorFixedPoint,\n",
    "    Uint8ActPerTensorFixedPoint,\n",
    ")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "def init_pad_input(x, input_channels, desired_channels=4):\n",
    "    padding = torch.zeros(1, input_channels * (desired_channels - 1), 32, 32)\n",
    "    return torch.cat((x, padding), 1)\n",
    "\n",
    "\n",
    "# try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bb5f126-1051-4a4e-bf7b-cc7f7e0b92c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________POST PTQ SCALES_________\n",
      "init_scale: tensor(0.0078)\n",
      "block_0_relu1: tensor(0.0039)\n",
      "block_0_relu2: tensor(0.0039)\n",
      "block_0_relu3: tensor(0.0039)\n",
      "block_0_weight_scale1: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "block_0_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_0_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "block_0_weight_scale_skip: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "block_1_quant_add_1: tensor(0.0039)\n",
      "block_1_relu1: tensor(0.0039)\n",
      "block_1_relu2: tensor(0.0039)\n",
      "block_1_relu3: tensor(0.0039)\n",
      "block_1_weight_scale1: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_1_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_1_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "block_2_quant_add_1: tensor(0.0039)\n",
      "block_2_relu1: tensor(0.0039)\n",
      "block_2_relu2: tensor(0.0039)\n",
      "block_2_relu3: tensor(0.0039)\n",
      "block_2_weight_scale1: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_2_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_2_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "combined_scale block0 after first conv1x1: 9.0\n",
      "combined_scale block0 after second conv3x3: 11.0\n",
      "combined_scale block0 after third conv1x1: 11.0\n",
      "combined_scale block0 after adding skip connection: -1.0\n",
      "combined_scale block0 after skip conv1x1: 10.0\n",
      "--------------------------------------------------------------\n",
      "combined_scale block1 after first conv1x1: 11.0\n",
      "combined_scale block1 after second conv3x3: 11.0\n",
      "combined_scale block1 after third conv1x1: 10.0\n",
      "combined_scale block1 after adding skip connection: -0.0\n",
      "--------------------------------------------------------------\n",
      "combined_scale block2 after first conv1x1: 11.0\n",
      "combined_scale block2 after second conv3x3: 11.0\n",
      "combined_scale block2 after third conv1x1: 10.0\n",
      "combined_scale block2 after adding skip connection: -0.0\n",
      "Golden::Brevitas:: [[[[  9  10 140 ...  12   5   2]\n",
      "   [ 12  16   1 ...   5   8   6]\n",
      "   [253   7   0 ...   0 111  65]\n",
      "   ...\n",
      "   [ 17  67   2 ...   3   2 117]\n",
      "   [  5  25  95 ... 205  73 118]\n",
      "   [  7 106  23 ... 115   4   0]]\n",
      "\n",
      "  [[  0  11 175 ...  84   6  25]\n",
      "   [ 73 118   9 ...  66  12   4]\n",
      "   [121   8   6 ...   6   0   8]\n",
      "   ...\n",
      "   [ 79  32  32 ...   5  76 199]\n",
      "   [  5   3  48 ...  11   2   8]\n",
      "   [  6  40  48 ...   3   5  55]]\n",
      "\n",
      "  [[  0 120   0 ...   0 219 115]\n",
      "   [ 21   0   0 ...   9 126  55]\n",
      "   [  0   0 195 ...  22 243  26]\n",
      "   ...\n",
      "   [  0   0   0 ...  14   0   8]\n",
      "   [ 29   0   0 ...   0   0   0]\n",
      "   [ 91   0 108 ...   5  41   0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 24  54  16 ...  91  12  18]\n",
      "   [ 60  14  23 ... 219  16   4]\n",
      "   [240  41  68 ...  13  16  15]\n",
      "   ...\n",
      "   [ 18  11  52 ... 131  52  44]\n",
      "   [ 14  13  32 ...  11   1  21]\n",
      "   [ 57  48   1 ... 112   7  10]]\n",
      "\n",
      "  [[ 20  12  16 ... 169  12  48]\n",
      "   [ 59   9 159 ...  13  19   3]\n",
      "   [ 14   8  23 ...  99  75   8]\n",
      "   ...\n",
      "   [ 87 108  82 ... 159  98  10]\n",
      "   [  4  13  15 ...  17  32   6]\n",
      "   [ 13  26  19 ...   6 114  94]]\n",
      "\n",
      "  [[ 72  75  75 ...  12  10   0]\n",
      "   [ 83 127  25 ...   0  63 177]\n",
      "   [  0 141   0 ... 128   0 133]\n",
      "   ...\n",
      "   [  0   8 161 ...   0   0  24]\n",
      "   [ 84   1 152 ...   0  92   1]\n",
      "   [  0  49   7 ...   0 101 107]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gagan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py:1271: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10/core/TensorImpl.h:1791.)\n",
      "  return super().rename(names)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\brevitas\\export\\onnx\\standard\\manager.py:26: UserWarning: ONNX opset version set to 13, override with opset_version=\n",
      "  warnings.warn(f\"ONNX opset version set to {DEFAULT_OPSET}, override with {ka}=\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "total_wts (143360,)\n",
      "AIE output::: tensor([[[[  9,  10, 139,  ...,  12,   5,   2],\n",
      "          [ 12,  16,   1,  ...,   5,   8,   6],\n",
      "          [253,   7,   0,  ...,   0, 111,  65],\n",
      "          ...,\n",
      "          [ 17,  67,   2,  ...,   3,   2, 117],\n",
      "          [  5,  25,  95,  ..., 205,  73, 117],\n",
      "          [  7, 106,  23,  ..., 115,   4,   0]],\n",
      "\n",
      "         [[  0,  10, 175,  ...,  83,   6,  25],\n",
      "          [ 74, 118,   9,  ...,  67,  12,   4],\n",
      "          [121,   8,   6,  ...,   7,   0,   8],\n",
      "          ...,\n",
      "          [ 79,  32,  31,  ...,   5,  76, 199],\n",
      "          [  5,   3,  49,  ...,  11,   3,   8],\n",
      "          [  6,  40,  48,  ...,   3,   5,  55]],\n",
      "\n",
      "         [[  0, 120,   0,  ...,   0, 219, 115],\n",
      "          [ 21,   0,   0,  ...,   9, 126,  55],\n",
      "          [  0,   0, 195,  ...,  22, 243,  26],\n",
      "          ...,\n",
      "          [  0,   0,   0,  ...,  14,   0,   9],\n",
      "          [ 29,   0,   0,  ...,   0,   0,   0],\n",
      "          [ 91,   0, 108,  ...,   4,  41,   0]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 24,  54,  16,  ...,  91,  13,  18],\n",
      "          [ 60,  13,  23,  ..., 219,  16,   4],\n",
      "          [239,  41,  68,  ...,  13,  16,  15],\n",
      "          ...,\n",
      "          [ 18,  11,  52,  ..., 131,  51,  44],\n",
      "          [ 14,  13,  32,  ...,  11,   0,  21],\n",
      "          [ 57,  48,   1,  ..., 112,   6,  10]],\n",
      "\n",
      "         [[ 20,  12,  16,  ..., 169,  12,  48],\n",
      "          [ 60,   9, 158,  ...,  13,  19,   3],\n",
      "          [ 14,   8,  23,  ..., 100,  75,   8],\n",
      "          ...,\n",
      "          [ 87, 108,  82,  ..., 160,  98,  10],\n",
      "          [  4,  13,  15,  ...,  17,  32,   6],\n",
      "          [ 13,  27,  19,  ...,   6, 114,  94]],\n",
      "\n",
      "         [[ 72,  75,  75,  ...,  12,  10,   0],\n",
      "          [ 83, 127,  24,  ...,   0,  63, 177],\n",
      "          [  0, 140,   0,  ..., 128,   0, 133],\n",
      "          ...,\n",
      "          [  0,   8, 161,  ...,   0,   0,  24],\n",
      "          [ 84,   1, 152,  ...,   0,  92,   1],\n",
      "          [  0,  49,   7,  ...,   0, 101, 107]]]], dtype=torch.uint8)\n",
      "<class 'torch.Tensor'>\n",
      "<class 'brevitas.quant_tensor.QuantTensor'>\n",
      "difference:: tensor(0.0156, grad_fn=<MaxBackward1>)\n",
      "rms:: tensor(0.0013, grad_fn=<SqrtBackward0>)\n",
      "_________POST PTQ SCALES_________\n",
      "init_scale: tensor(0.0078)\n",
      "block_0_relu1: tensor(0.0039)\n",
      "block_0_relu2: tensor(0.0039)\n",
      "block_0_relu3: tensor(0.0039)\n",
      "block_0_weight_scale1: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "block_0_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_0_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "block_0_weight_scale_skip: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "block_1_quant_add_1: tensor(0.0039)\n",
      "block_1_relu1: tensor(0.0039)\n",
      "block_1_relu2: tensor(0.0039)\n",
      "block_1_relu3: tensor(0.0039)\n",
      "block_1_weight_scale1: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_1_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_1_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "block_2_quant_add_1: tensor(0.0039)\n",
      "block_2_relu1: tensor(0.0039)\n",
      "block_2_relu2: tensor(0.0039)\n",
      "block_2_relu3: tensor(0.0039)\n",
      "block_2_weight_scale1: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_2_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_2_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "combined_scale block0 after first conv1x1: 9.0\n",
      "combined_scale block0 after second conv3x3: 11.0\n",
      "combined_scale block0 after third conv1x1: 11.0\n",
      "combined_scale block0 after adding skip connection: -1.0\n",
      "combined_scale block0 after skip conv1x1: 10.0\n",
      "--------------------------------------------------------------\n",
      "combined_scale block1 after first conv1x1: 11.0\n",
      "combined_scale block1 after second conv3x3: 11.0\n",
      "combined_scale block1 after third conv1x1: 10.0\n",
      "combined_scale block1 after adding skip connection: -0.0\n",
      "--------------------------------------------------------------\n",
      "combined_scale block2 after first conv1x1: 11.0\n",
      "combined_scale block2 after second conv3x3: 11.0\n",
      "combined_scale block2 after third conv1x1: 10.0\n",
      "combined_scale block2 after adding skip connection: -0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_10056\\2170453449.py:256: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:367.)\n",
      "  print(\"difference::\",torch.max(torch.abs(ofm_mem_fmt*block_2_relu_3 - q_bottleneck_out)))\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_10056\\2170453449.py:267: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:367.)\n",
      "  sq_abs = torch.square(torch.abs(ofm_mem_fmt*block_2_relu_3 - q_bottleneck_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden::Brevitas:: [[[[  0   0 110 ... 133   0   0]\n",
      "   [  0 121   0 ...   0   0   0]\n",
      "   [116  44 136 ...   0   0   0]\n",
      "   ...\n",
      "   [  0  30   0 ...  93   0   0]\n",
      "   [ 75   0   0 ...   0  60   0]\n",
      "   [244  24   0 ...  38 106  33]]\n",
      "\n",
      "  [[ 17   1   9 ...   5  72  91]\n",
      "   [130  87  15 ...   5 114   7]\n",
      "   [  0 118 170 ...   2   7  79]\n",
      "   ...\n",
      "   [  1 113  19 ...  12  16  77]\n",
      "   [ 13   8  28 ...   8  14  41]\n",
      "   [124  73  26 ...  15  50   7]]\n",
      "\n",
      "  [[  0 115   2 ...  23   7   0]\n",
      "   [  0   0   0 ...   0   0   0]\n",
      "   [ 60   0   6 ... 101   0   1]\n",
      "   ...\n",
      "   [  0  73   0 ...   0   4  59]\n",
      "   [  0 115  52 ...   0   2   0]\n",
      "   [  0  49  19 ...  33 118   4]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 10  18   0 ...   0 228   0]\n",
      "   [  0   0   0 ...   0   0   3]\n",
      "   [100  29   3 ...   0 111  38]\n",
      "   ...\n",
      "   [  8   0   0 ...   0   1   0]\n",
      "   [ 15   0  25 ...   1   0   0]\n",
      "   [228  49   0 ...   5  31  95]]\n",
      "\n",
      "  [[ 45  13   6 ...  92   7   9]\n",
      "   [  0 223 255 ...  72   4   6]\n",
      "   [  7  63   1 ... 152  29  97]\n",
      "   ...\n",
      "   [ 37   0   5 ...  64  58  11]\n",
      "   [  0  62  10 ...  53  70   0]\n",
      "   [  5 156  28 ...  63  12 192]]\n",
      "\n",
      "  [[  3   0  67 ... 145  92   8]\n",
      "   [  0   1 207 ...   0   0  17]\n",
      "   [191  22   0 ...   0  87 105]\n",
      "   ...\n",
      "   [ 11  65  27 ...   0   0  26]\n",
      "   [ 14   0  33 ...   0   0 174]\n",
      "   [ 76   4   0 ...   0   0  48]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gagan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\brevitas\\export\\onnx\\standard\\manager.py:26: UserWarning: ONNX opset version set to 13, override with opset_version=\n",
      "  warnings.warn(f\"ONNX opset version set to {DEFAULT_OPSET}, override with {ka}=\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "total_wts (143360,)\n",
      "AIE output::: tensor([[[[  0,   0, 110,  ..., 133,   0,   0],\n",
      "          [  0, 121,   0,  ...,   0,   0,   0],\n",
      "          [116,  44, 136,  ...,   0,   0,   0],\n",
      "          ...,\n",
      "          [  0,  30,   0,  ...,  93,   0,   0],\n",
      "          [ 75,   0,   0,  ...,   0,  60,   0],\n",
      "          [244,  24,   0,  ...,  38, 108,  33]],\n",
      "\n",
      "         [[ 17,   1,   9,  ...,   5,  72,  91],\n",
      "          [129,  87,  16,  ...,   4, 114,   7],\n",
      "          [  0, 118, 170,  ...,   2,   6,  79],\n",
      "          ...,\n",
      "          [  1, 113,  19,  ...,  12,  16,  77],\n",
      "          [ 13,   8,  28,  ...,   8,  14,  41],\n",
      "          [124,  73,  26,  ...,  14,  48,   7]],\n",
      "\n",
      "         [[  0, 115,   2,  ...,  23,   7,   0],\n",
      "          [  0,   0,   0,  ...,   0,   0,   0],\n",
      "          [ 60,   0,   5,  ..., 101,   0,   1],\n",
      "          ...,\n",
      "          [  0,  73,   0,  ...,   0,   4,  59],\n",
      "          [  0, 115,  52,  ...,   1,   2,   0],\n",
      "          [  0,  49,  19,  ...,  33, 118,   4]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 10,  19,   0,  ...,   0, 228,   0],\n",
      "          [  0,   0,   0,  ...,   0,   0,   3],\n",
      "          [100,  29,   3,  ...,   0, 111,  38],\n",
      "          ...,\n",
      "          [  8,   0,   0,  ...,   0,   1,   0],\n",
      "          [ 15,   0,  25,  ...,   0,   0,   0],\n",
      "          [228,  49,   0,  ...,   5,  31,  95]],\n",
      "\n",
      "         [[ 45,  13,   6,  ...,  92,   7,   9],\n",
      "          [  0, 223, 255,  ...,  72,   5,   6],\n",
      "          [  7,  63,   1,  ..., 152,  30,  97],\n",
      "          ...,\n",
      "          [ 37,   0,   5,  ...,  64,  59,  11],\n",
      "          [  0,  62,  10,  ...,  53,  70,   0],\n",
      "          [  5, 156,  28,  ...,  63,  11, 192]],\n",
      "\n",
      "         [[  3,   0,  67,  ..., 145,  92,   7],\n",
      "          [  0,   1, 207,  ...,   0,   0,  17],\n",
      "          [190,  22,   0,  ...,   0,  87, 105],\n",
      "          ...,\n",
      "          [ 11,  65,  27,  ...,   0,   0,  26],\n",
      "          [ 14,   0,  33,  ...,   0,   0, 174],\n",
      "          [ 76,   4,   0,  ...,   0,   0,  48]]]], dtype=torch.uint8)\n",
      "<class 'torch.Tensor'>\n",
      "<class 'brevitas.quant_tensor.QuantTensor'>\n",
      "difference:: tensor(0.0156, grad_fn=<MaxBackward1>)\n",
      "rms:: tensor(0.0014, grad_fn=<SqrtBackward0>)\n",
      "_________POST PTQ SCALES_________\n",
      "init_scale: tensor(0.0078)\n",
      "block_0_relu1: tensor(0.0039)\n",
      "block_0_relu2: tensor(0.0039)\n",
      "block_0_relu3: tensor(0.0039)\n",
      "block_0_weight_scale1: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "block_0_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_0_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "block_0_weight_scale_skip: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "block_1_quant_add_1: tensor(0.0039)\n",
      "block_1_relu1: tensor(0.0039)\n",
      "block_1_relu2: tensor(0.0039)\n",
      "block_1_relu3: tensor(0.0039)\n",
      "block_1_weight_scale1: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_1_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_1_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "block_2_quant_add_1: tensor(0.0039)\n",
      "block_2_relu1: tensor(0.0039)\n",
      "block_2_relu2: tensor(0.0039)\n",
      "block_2_relu3: tensor(0.0039)\n",
      "block_2_weight_scale1: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_2_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_2_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "combined_scale block0 after first conv1x1: 9.0\n",
      "combined_scale block0 after second conv3x3: 11.0\n",
      "combined_scale block0 after third conv1x1: 11.0\n",
      "combined_scale block0 after adding skip connection: -1.0\n",
      "combined_scale block0 after skip conv1x1: 10.0\n",
      "--------------------------------------------------------------\n",
      "combined_scale block1 after first conv1x1: 11.0\n",
      "combined_scale block1 after second conv3x3: 11.0\n",
      "combined_scale block1 after third conv1x1: 10.0\n",
      "combined_scale block1 after adding skip connection: -0.0\n",
      "--------------------------------------------------------------\n",
      "combined_scale block2 after first conv1x1: 11.0\n",
      "combined_scale block2 after second conv3x3: 11.0\n",
      "combined_scale block2 after third conv1x1: 10.0\n",
      "combined_scale block2 after adding skip connection: -0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_10056\\2170453449.py:256: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:367.)\n",
      "  print(\"difference::\",torch.max(torch.abs(ofm_mem_fmt*block_2_relu_3 - q_bottleneck_out)))\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_10056\\2170453449.py:267: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:367.)\n",
      "  sq_abs = torch.square(torch.abs(ofm_mem_fmt*block_2_relu_3 - q_bottleneck_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden::Brevitas:: [[[[  7  15  68 ...  24  36  69]\n",
      "   [124  31   0 ...   0  84   1]\n",
      "   [ 71 170  91 ...   0 121   0]\n",
      "   ...\n",
      "   [  1 106 131 ...   0  94   0]\n",
      "   [  3   0   1 ...   4  13   5]\n",
      "   [  0   0 116 ... 119  95  49]]\n",
      "\n",
      "  [[252 251   3 ... 255  84   1]\n",
      "   [  0   0 169 ...  11 174 250]\n",
      "   [171   3  99 ...  41   9  22]\n",
      "   ...\n",
      "   [108   7   7 ... 126   6  58]\n",
      "   [ 28  24  13 ...   6   3  75]\n",
      "   [202   4   3 ... 105   2  84]]\n",
      "\n",
      "  [[  0  83 249 ... 192   9  53]\n",
      "   [  7  27   0 ... 171   3   1]\n",
      "   [ 48 123   9 ... 104 140   6]\n",
      "   ...\n",
      "   [  6  30   0 ... 148  16   0]\n",
      "   [107  34 104 ...   1   6  44]\n",
      "   [  3 114   0 ...   0 108  75]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128  64   5 ...   5   8  46]\n",
      "   [203  30 218 ...   0  13  91]\n",
      "   [ 22   0 113 ...   5  12   1]\n",
      "   ...\n",
      "   [ 81   0   1 ...   7  72   6]\n",
      "   [ 66  44   7 ...  26   7   3]\n",
      "   [ 35   0   0 ... 114   3  19]]\n",
      "\n",
      "  [[  0   0 169 ...   0   0  29]\n",
      "   [ 23   0 186 ...   8 120 127]\n",
      "   [  0   9   0 ...   0   7 196]\n",
      "   ...\n",
      "   [  0   5  32 ...  27  85  56]\n",
      "   [  0 134   5 ...   0  12   5]\n",
      "   [ 40  67   8 ... 147   8   7]]\n",
      "\n",
      "  [[ 90   0   1 ...   0  96   4]\n",
      "   [ 84   0   2 ...   0   0   4]\n",
      "   [  8 107  54 ...   0   5   0]\n",
      "   ...\n",
      "   [  0   0  85 ...   0   7   1]\n",
      "   [  5   2   0 ... 247   0   0]\n",
      "   [  5  11  79 ...   7  88 107]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gagan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\brevitas\\export\\onnx\\standard\\manager.py:26: UserWarning: ONNX opset version set to 13, override with opset_version=\n",
      "  warnings.warn(f\"ONNX opset version set to {DEFAULT_OPSET}, override with {ka}=\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "total_wts (143360,)\n",
      "AIE output::: tensor([[[[  7,  15,  68,  ...,  24,  36,  69],\n",
      "          [125,  31,   0,  ...,   0,  84,   1],\n",
      "          [ 71, 170,  91,  ...,   0, 121,   0],\n",
      "          ...,\n",
      "          [  1, 106, 131,  ...,   0,  93,   0],\n",
      "          [  3,   0,   1,  ...,   4,  13,   5],\n",
      "          [  0,   0, 116,  ..., 119,  95,  48]],\n",
      "\n",
      "         [[252, 251,   3,  ..., 255,  84,   1],\n",
      "          [  0,   0, 169,  ...,  11, 174, 250],\n",
      "          [171,   3,  99,  ...,  41,   9,  22],\n",
      "          ...,\n",
      "          [108,   6,   7,  ..., 126,   6,  58],\n",
      "          [ 28,  24,  13,  ...,   6,   3,  75],\n",
      "          [203,   4,   3,  ..., 105,   2,  84]],\n",
      "\n",
      "         [[  0,  83, 249,  ..., 192,   9,  53],\n",
      "          [  7,  27,   0,  ..., 171,   3,   1],\n",
      "          [ 48, 124,   9,  ..., 104, 140,   6],\n",
      "          ...,\n",
      "          [  6,  30,   0,  ..., 148,  16,   0],\n",
      "          [105,  34, 105,  ...,   1,   5,  44],\n",
      "          [  3, 114,   0,  ...,   0, 108,  75]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[128,  65,   5,  ...,   5,   8,  46],\n",
      "          [203,  30, 218,  ...,   0,  13,  91],\n",
      "          [ 22,   0, 113,  ...,   5,  13,   1],\n",
      "          ...,\n",
      "          [ 81,   0,   1,  ...,   7,  72,   6],\n",
      "          [ 66,  44,   7,  ...,  26,   7,   3],\n",
      "          [ 35,   0,   0,  ..., 114,   3,  19]],\n",
      "\n",
      "         [[  0,   0, 170,  ...,   0,   0,  29],\n",
      "          [ 23,   0, 186,  ...,   8, 120, 127],\n",
      "          [  0,   9,   0,  ...,   0,   7, 196],\n",
      "          ...,\n",
      "          [  0,   5,  32,  ...,  27,  85,  56],\n",
      "          [  0, 134,   5,  ...,   0,  12,   5],\n",
      "          [ 40,  67,   8,  ..., 147,   8,   7]],\n",
      "\n",
      "         [[ 90,   0,   1,  ...,   0,  96,   4],\n",
      "          [ 84,   0,   2,  ...,   0,   0,   4],\n",
      "          [  8, 107,  54,  ...,   0,   5,   0],\n",
      "          ...,\n",
      "          [  0,   0,  85,  ...,   0,   7,   1],\n",
      "          [  5,   2,   0,  ..., 247,   0,   0],\n",
      "          [  5,  11,  79,  ...,   7,  88, 107]]]], dtype=torch.uint8)\n",
      "<class 'torch.Tensor'>\n",
      "<class 'brevitas.quant_tensor.QuantTensor'>\n",
      "difference:: tensor(0.0156, grad_fn=<MaxBackward1>)\n",
      "rms:: tensor(0.0013, grad_fn=<SqrtBackward0>)\n",
      "_________POST PTQ SCALES_________\n",
      "init_scale: tensor(0.0078)\n",
      "block_0_relu1: tensor(0.0039)\n",
      "block_0_relu2: tensor(0.0039)\n",
      "block_0_relu3: tensor(0.0039)\n",
      "block_0_weight_scale1: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "block_0_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_0_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "block_0_weight_scale_skip: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "block_1_quant_add_1: tensor(0.0039)\n",
      "block_1_relu1: tensor(0.0039)\n",
      "block_1_relu2: tensor(0.0039)\n",
      "block_1_relu3: tensor(0.0039)\n",
      "block_1_weight_scale1: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_1_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_1_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "block_2_quant_add_1: tensor(0.0039)\n",
      "block_2_relu1: tensor(0.0039)\n",
      "block_2_relu2: tensor(0.0039)\n",
      "block_2_relu3: tensor(0.0039)\n",
      "block_2_weight_scale1: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_2_weight_scale2: tensor(0.0005, grad_fn=<DivBackward0>)\n",
      "block_2_weight_scale3: tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "--------------------------------------------------------------\n",
      "combined_scale block0 after first conv1x1: 9.0\n",
      "combined_scale block0 after second conv3x3: 11.0\n",
      "combined_scale block0 after third conv1x1: 11.0\n",
      "combined_scale block0 after adding skip connection: -1.0\n",
      "combined_scale block0 after skip conv1x1: 10.0\n",
      "--------------------------------------------------------------\n",
      "combined_scale block1 after first conv1x1: 11.0\n",
      "combined_scale block1 after second conv3x3: 11.0\n",
      "combined_scale block1 after third conv1x1: 10.0\n",
      "combined_scale block1 after adding skip connection: -0.0\n",
      "--------------------------------------------------------------\n",
      "combined_scale block2 after first conv1x1: 11.0\n",
      "combined_scale block2 after second conv3x3: 11.0\n",
      "combined_scale block2 after third conv1x1: 10.0\n",
      "combined_scale block2 after adding skip connection: -0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_10056\\2170453449.py:256: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:367.)\n",
      "  print(\"difference::\",torch.max(torch.abs(ofm_mem_fmt*block_2_relu_3 - q_bottleneck_out)))\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_10056\\2170453449.py:267: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:367.)\n",
      "  sq_abs = torch.square(torch.abs(ofm_mem_fmt*block_2_relu_3 - q_bottleneck_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden::Brevitas:: [[[[  4   4   0 ... 109 185   1]\n",
      "   [  0  24   0 ...   0   0   0]\n",
      "   [  0   0   0 ...   0 138   2]\n",
      "   ...\n",
      "   [ 79   0   0 ...  29   1  89]\n",
      "   [  2 137  73 ...  27 130   0]\n",
      "   [  2   0   0 ...  50   0   0]]\n",
      "\n",
      "  [[219  91  95 ...   0   6  86]\n",
      "   [ 13  22  68 ...   5   0   0]\n",
      "   [  0  90   0 ...   4   0   2]\n",
      "   ...\n",
      "   [  0   0 149 ...   0   0 145]\n",
      "   [ 34  79 130 ...   0  27   0]\n",
      "   [113  40   0 ...   0   0  42]]\n",
      "\n",
      "  [[  3  56   8 ...  75   8 111]\n",
      "   [ 49   7   3 ...   4  15  12]\n",
      "   [116   9  85 ...   6   4 235]\n",
      "   ...\n",
      "   [116  70 218 ...   7   3 146]\n",
      "   [ 63  13  32 ...   4   9  58]\n",
      "   [127  95   7 ...  13  17 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[147   0  41 ...  81 216   0]\n",
      "   [  0 164   3 ... 242   0 126]\n",
      "   [  0   0 116 ...  35   0   0]\n",
      "   ...\n",
      "   [ 40   0   0 ...   0 198   3]\n",
      "   [  0  83   0 ... 151   0   0]\n",
      "   [  0   0   0 ... 173 237   0]]\n",
      "\n",
      "  [[ 93  41  52 ...  53 202  13]\n",
      "   [ 16  30 190 ...  22  23 206]\n",
      "   [ 18  19  28 ...  17  98  12]\n",
      "   ...\n",
      "   [ 14 102  36 ...  71  57  96]\n",
      "   [ 19  47  16 ...  85  17  39]\n",
      "   [ 11  13 181 ...  27  15  20]]\n",
      "\n",
      "  [[107   4  54 ... 118   3   4]\n",
      "   [ 55  90  11 ...  59  19  24]\n",
      "   [ 48  10  48 ...  14  60  43]\n",
      "   ...\n",
      "   [  6  30   4 ...  12  18   9]\n",
      "   [  3 118  94 ...  85  11   4]\n",
      "   [ 45  14  38 ...  36  10   6]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gagan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\brevitas\\export\\onnx\\standard\\manager.py:26: UserWarning: ONNX opset version set to 13, override with opset_version=\n",
      "  warnings.warn(f\"ONNX opset version set to {DEFAULT_OPSET}, override with {ka}=\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "total_wts (143360,)\n",
      "AIE output::: tensor([[[[  4,   4,   0,  ..., 109, 185,   1],\n",
      "          [  0,  24,   0,  ...,   0,   0,   0],\n",
      "          [  0,   0,   0,  ...,   0, 138,   2],\n",
      "          ...,\n",
      "          [ 79,   0,   0,  ...,  28,   1,  89],\n",
      "          [  2, 138,  73,  ...,  27, 130,   0],\n",
      "          [  2,   0,   0,  ...,  50,   0,   0]],\n",
      "\n",
      "         [[218,  91,  95,  ...,   0,   6,  86],\n",
      "          [ 13,  22,  68,  ...,   4,   0,   0],\n",
      "          [  0,  90,   0,  ...,   4,   0,   2],\n",
      "          ...,\n",
      "          [  0,   0, 149,  ...,   0,   0, 146],\n",
      "          [ 34,  79, 130,  ...,   0,  27,   0],\n",
      "          [113,  40,   0,  ...,   0,   0,  42]],\n",
      "\n",
      "         [[  4,  56,   8,  ...,  75,   7, 111],\n",
      "          [ 49,   7,   3,  ...,   4,  14,  12],\n",
      "          [116,   9,  85,  ...,   6,   4, 235],\n",
      "          ...,\n",
      "          [116,  70, 218,  ...,   7,   3, 146],\n",
      "          [ 63,  13,  31,  ...,   4,   9,  58],\n",
      "          [127,  95,   7,  ...,  13,  17, 255]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[147,   0,  42,  ...,  81, 216,   0],\n",
      "          [  0, 164,   2,  ..., 242,   0, 126],\n",
      "          [  0,   0, 117,  ...,  35,   0,   0],\n",
      "          ...,\n",
      "          [ 40,   0,   0,  ...,   0, 198,   3],\n",
      "          [  0,  83,   0,  ..., 151,   0,   0],\n",
      "          [  0,   0,   0,  ..., 173, 237,   0]],\n",
      "\n",
      "         [[ 93,  40,  51,  ...,  53, 202,  13],\n",
      "          [ 16,  30, 190,  ...,  22,  23, 205],\n",
      "          [ 18,  19,  28,  ...,  18,  99,  12],\n",
      "          ...,\n",
      "          [ 14, 102,  36,  ...,  71,  57,  96],\n",
      "          [ 19,  47,  16,  ...,  85,  17,  39],\n",
      "          [ 12,  13, 180,  ...,  27,  15,  20]],\n",
      "\n",
      "         [[107,   5,  55,  ..., 118,   3,   4],\n",
      "          [ 55,  90,  10,  ...,  59,  19,  24],\n",
      "          [ 47,  10,  48,  ...,  14,  60,  43],\n",
      "          ...,\n",
      "          [  6,  30,   4,  ...,  12,  18,   9],\n",
      "          [  3, 118,  94,  ...,  85,  12,   4],\n",
      "          [ 45,  14,  38,  ...,  36,  10,   6]]]], dtype=torch.uint8)\n",
      "<class 'torch.Tensor'>\n",
      "<class 'brevitas.quant_tensor.QuantTensor'>\n",
      "difference:: tensor(0.0156, grad_fn=<MaxBackward1>)\n",
      "rms:: tensor(0.0013, grad_fn=<SqrtBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_10056\\2170453449.py:256: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:367.)\n",
      "  print(\"difference::\",torch.max(torch.abs(ofm_mem_fmt*block_2_relu_3 - q_bottleneck_out)))\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_10056\\2170453449.py:267: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:367.)\n",
      "  sq_abs = torch.square(torch.abs(ofm_mem_fmt*block_2_relu_3 - q_bottleneck_out))\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 4):\n",
    "\n",
    "    class QuantBottleneck_projected(nn.Module):\n",
    "        expansion = 4\n",
    "\n",
    "        def __init__(self, in_planes=64, planes=64):\n",
    "            super(QuantBottleneck_projected, self).__init__()\n",
    "            # block 0\n",
    "            self.quant_id_1 = QuantIdentity(\n",
    "                act_quant=Int8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block0_conv1 = QuantConv2d(\n",
    "                in_planes,\n",
    "                planes,\n",
    "                kernel_size=1,\n",
    "                bit_width=8,\n",
    "                weight_bit_width=8,\n",
    "                bias=False,\n",
    "                weight_quant=Int8WeightPerTensorFixedPoint,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block0_conv2 = QuantConv2d(\n",
    "                planes,\n",
    "                planes,\n",
    "                kernel_size=3,\n",
    "                bit_width=8,\n",
    "                weight_bit_width=8,\n",
    "                bias=False,\n",
    "                padding=1,\n",
    "                padding_mode=\"zeros\",\n",
    "                weight_quant=Int8WeightPerTensorFixedPoint,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block0_conv3 = QuantConv2d(\n",
    "                planes,\n",
    "                self.expansion * planes,\n",
    "                kernel_size=1,\n",
    "                bit_width=8,\n",
    "                weight_bit_width=8,\n",
    "                bias=False,\n",
    "                weight_quant=Int8WeightPerTensorFixedPoint,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block0_relu1 = QuantReLU(\n",
    "                act_quant=Uint8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block0_relu2 = QuantReLU(\n",
    "                act_quant=Uint8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block0_relu3 = QuantReLU(\n",
    "                act_quant=Uint8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "\n",
    "            self.shortcut = QuantConv2d(\n",
    "                in_planes,\n",
    "                self.expansion * planes,\n",
    "                kernel_size=1,\n",
    "                bit_width=8,\n",
    "                weight_bit_width=8,\n",
    "                bias=False,\n",
    "                weight_quant=Int8WeightPerTensorFixedPoint,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "\n",
    "            # block 1\n",
    "            self.quant_block1_conv1 = QuantConv2d(\n",
    "                self.expansion * in_planes,\n",
    "                planes,\n",
    "                kernel_size=1,\n",
    "                bit_width=8,\n",
    "                weight_bit_width=8,\n",
    "                bias=False,\n",
    "                weight_quant=Int8WeightPerTensorFixedPoint,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block1_conv2 = QuantConv2d(\n",
    "                planes,\n",
    "                planes,\n",
    "                kernel_size=3,\n",
    "                bit_width=8,\n",
    "                weight_bit_width=8,\n",
    "                bias=False,\n",
    "                padding=1,\n",
    "                padding_mode=\"zeros\",\n",
    "                weight_quant=Int8WeightPerTensorFixedPoint,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block1_conv3 = QuantConv2d(\n",
    "                planes,\n",
    "                self.expansion * planes,\n",
    "                kernel_size=1,\n",
    "                bit_width=8,\n",
    "                weight_bit_width=8,\n",
    "                bias=False,\n",
    "                weight_quant=Int8WeightPerTensorFixedPoint,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block1_relu1 = QuantReLU(\n",
    "                act_quant=Uint8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block1_relu2 = QuantReLU(\n",
    "                act_quant=Uint8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block1_relu3 = QuantReLU(\n",
    "                act_quant=Uint8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "\n",
    "            self.quant_add_1 = QuantIdentity(\n",
    "                act_quant=Int8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            # Quant_add_1 shares the scale factors with block0_relu3, however one is signed and the other one is unsigned\n",
    "            self.quant_add_1.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl = (\n",
    "                self.quant_block0_relu3.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl\n",
    "            )\n",
    "            self.quant_add_1.act_quant.fused_activation_quant_proxy.tensor_quant.int_scaling_impl = (\n",
    "                self.quant_block0_relu3.act_quant.fused_activation_quant_proxy.tensor_quant.int_scaling_impl\n",
    "            )\n",
    "\n",
    "            # block 2\n",
    "            self.quant_block2_conv1 = QuantConv2d(\n",
    "                self.expansion * in_planes,\n",
    "                planes,\n",
    "                kernel_size=1,\n",
    "                bit_width=8,\n",
    "                weight_bit_width=8,\n",
    "                bias=False,\n",
    "                weight_quant=Int8WeightPerTensorFixedPoint,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block2_conv2 = QuantConv2d(\n",
    "                planes,\n",
    "                planes,\n",
    "                kernel_size=3,\n",
    "                bit_width=8,\n",
    "                weight_bit_width=8,\n",
    "                bias=False,\n",
    "                padding=1,\n",
    "                padding_mode=\"zeros\",\n",
    "                weight_quant=Int8WeightPerTensorFixedPoint,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block2_conv3 = QuantConv2d(\n",
    "                planes,\n",
    "                self.expansion * planes,\n",
    "                kernel_size=1,\n",
    "                bit_width=8,\n",
    "                weight_bit_width=8,\n",
    "                bias=False,\n",
    "                weight_quant=Int8WeightPerTensorFixedPoint,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block2_relu1 = QuantReLU(\n",
    "                act_quant=Uint8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block2_relu2 = QuantReLU(\n",
    "                act_quant=Uint8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            self.quant_block2_relu3 = QuantReLU(\n",
    "                act_quant=Uint8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "\n",
    "            self.quant_add_2 = QuantIdentity(\n",
    "                act_quant=Int8ActPerTensorFixedPoint,\n",
    "                bit_width=8,\n",
    "                return_quant_tensor=True,\n",
    "            )\n",
    "            # Quant_add_1 shares the scale factors with block0_relu3, however one is signed and the other one is unsigned\n",
    "            self.quant_add_2.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl = (\n",
    "                self.quant_block1_relu3.act_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl\n",
    "            )\n",
    "            self.quant_add_2.act_quant.fused_activation_quant_proxy.tensor_quant.int_scaling_impl = (\n",
    "                self.quant_block1_relu3.act_quant.fused_activation_quant_proxy.tensor_quant.int_scaling_impl\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            out_q = self.quant_id_1(x)\n",
    "            out_rhs = self.quant_block0_conv1(out_q)\n",
    "            out_rhs = self.quant_block0_relu1(out_rhs)\n",
    "            out_rhs = self.quant_block0_conv2(out_rhs)\n",
    "            out_rhs = self.quant_block0_relu2(out_rhs)\n",
    "            out_rhs = self.quant_block0_conv3(out_rhs)\n",
    "            out_rhs = self.quant_id_1(out_rhs)\n",
    "            out_lhs = self.shortcut(out_q)\n",
    "            out_lhs = self.quant_id_1(out_lhs)\n",
    "            out_block0 = out_rhs + out_lhs\n",
    "            out_block0 = self.quant_block0_relu3(out_block0)\n",
    "            # block 1\n",
    "            out_rhs1 = self.quant_block1_conv1(out_block0)\n",
    "            out_rhs1 = self.quant_block1_relu1(out_rhs1)\n",
    "            out_rhs1 = self.quant_block1_conv2(out_rhs1)\n",
    "            out_rhs1 = self.quant_block1_relu2(out_rhs1)\n",
    "            out_rhs1 = self.quant_block1_conv3(out_rhs1)\n",
    "            out_rhs1 = self.quant_add_1(out_rhs1)\n",
    "            out_block1 = out_block0 + out_rhs1\n",
    "            # out_block1=out_block0\n",
    "            out_block1 = self.quant_block1_relu3(out_block1)\n",
    "\n",
    "            # block 1\n",
    "            out_rhs2 = self.quant_block2_conv1(out_block1)\n",
    "            out_rhs2 = self.quant_block2_relu1(out_rhs2)\n",
    "            out_rhs2 = self.quant_block2_conv2(out_rhs2)\n",
    "            out_rhs2 = self.quant_block2_relu2(out_rhs2)\n",
    "            out_rhs2 = self.quant_block2_conv3(out_rhs2)\n",
    "            out_rhs2 = self.quant_add_2(out_rhs2)\n",
    "            out_block2 = out_block1 + out_rhs2\n",
    "            # out_block1=out_block0\n",
    "            out_block2 = self.quant_block2_relu3(out_block2)\n",
    "\n",
    "            return out_block2\n",
    "\n",
    "    input = torch.randn(1, 64, 32, 32)\n",
    "    quant_bottleneck_model = QuantBottleneck_projected()\n",
    "\n",
    "    quant_id_1 = QuantIdentity(\n",
    "        act_quant=Int8ActPerTensorFixedPoint, bit_width=8, return_quant_tensor=True\n",
    "    )\n",
    "    quant_bottleneck_model.eval()\n",
    "    quant_id_1.eval()\n",
    "    # from brevitas_examples.imagenet_classification.ptq.ptq_common import calibrate\n",
    "    # calibrate([(torch.rand(32,64,32,32), 1) for _ in range(5)], quant_bottleneck_model)\n",
    "    # #\n",
    "    # from brevitas.fx import brevitas_symbolic_trace\n",
    "    # model = brevitas_symbolic_trace(quant_bottleneck_model)\n",
    "    # print(model.graph)\n",
    "\n",
    "    init_scale = quant_bottleneck_model.quant_id_1.quant_act_scale()\n",
    "    block_0_relu_1 = quant_bottleneck_model.quant_block0_relu1.quant_act_scale()\n",
    "    block_0_relu_2 = quant_bottleneck_model.quant_block0_relu2.quant_act_scale()\n",
    "    block_0_relu_3 = quant_bottleneck_model.quant_block0_relu3.quant_act_scale()\n",
    "\n",
    "    block_0_weight_scale1 = (\n",
    "        quant_bottleneck_model.quant_block0_conv1.quant_weight_scale()\n",
    "    )\n",
    "    block_0_weight_scale2 = (\n",
    "        quant_bottleneck_model.quant_block0_conv2.quant_weight_scale()\n",
    "    )\n",
    "    block_0_weight_scale3 = (\n",
    "        quant_bottleneck_model.quant_block0_conv3.quant_weight_scale()\n",
    "    )\n",
    "    block_0_weight_scale_skip = quant_bottleneck_model.shortcut.quant_weight_scale()\n",
    "\n",
    "    # Block 2\n",
    "    block_1_relu_1 = quant_bottleneck_model.quant_block1_relu1.quant_act_scale()\n",
    "    block_1_relu_2 = quant_bottleneck_model.quant_block1_relu2.quant_act_scale()\n",
    "    block_1_relu_3 = quant_bottleneck_model.quant_block1_relu3.quant_act_scale()\n",
    "\n",
    "    block_1_weight_scale1 = (\n",
    "        quant_bottleneck_model.quant_block1_conv1.quant_weight_scale()\n",
    "    )\n",
    "    block_1_weight_scale2 = (\n",
    "        quant_bottleneck_model.quant_block1_conv2.quant_weight_scale()\n",
    "    )\n",
    "    block_1_weight_scale3 = (\n",
    "        quant_bottleneck_model.quant_block1_conv3.quant_weight_scale()\n",
    "    )\n",
    "    block_1_quant_add_1 = quant_bottleneck_model.quant_add_1.quant_act_scale()\n",
    "\n",
    "    # Block 3\n",
    "    block_2_relu_1 = quant_bottleneck_model.quant_block2_relu1.quant_act_scale()\n",
    "    block_2_relu_2 = quant_bottleneck_model.quant_block2_relu2.quant_act_scale()\n",
    "    block_2_relu_3 = quant_bottleneck_model.quant_block2_relu3.quant_act_scale()\n",
    "\n",
    "    block_2_weight_scale1 = (\n",
    "        quant_bottleneck_model.quant_block2_conv1.quant_weight_scale()\n",
    "    )\n",
    "    block_2_weight_scale2 = (\n",
    "        quant_bottleneck_model.quant_block2_conv2.quant_weight_scale()\n",
    "    )\n",
    "    block_2_weight_scale3 = (\n",
    "        quant_bottleneck_model.quant_block2_conv3.quant_weight_scale()\n",
    "    )\n",
    "    block_2_quant_add_1 = quant_bottleneck_model.quant_add_2.quant_act_scale()\n",
    "\n",
    "    block_0_int_weight_1 = quant_bottleneck_model.quant_block0_conv1.quant_weight().int(\n",
    "        float_datatype=True\n",
    "    )\n",
    "    block_0_int_weight_2 = quant_bottleneck_model.quant_block0_conv2.quant_weight().int(\n",
    "        float_datatype=True\n",
    "    )\n",
    "    block_0_int_weight_3 = quant_bottleneck_model.quant_block0_conv3.quant_weight().int(\n",
    "        float_datatype=True\n",
    "    )\n",
    "    block_0_int_weight_skip = quant_bottleneck_model.shortcut.quant_weight().int(\n",
    "        float_datatype=True\n",
    "    )\n",
    "\n",
    "    block_1_int_weight_1 = quant_bottleneck_model.quant_block1_conv1.quant_weight().int(\n",
    "        float_datatype=True\n",
    "    )\n",
    "    block_1_int_weight_2 = quant_bottleneck_model.quant_block1_conv2.quant_weight().int(\n",
    "        float_datatype=True\n",
    "    )\n",
    "    block_1_int_weight_3 = quant_bottleneck_model.quant_block1_conv3.quant_weight().int(\n",
    "        float_datatype=True\n",
    "    )\n",
    "\n",
    "    block_2_int_weight_1 = quant_bottleneck_model.quant_block2_conv1.quant_weight().int(\n",
    "        float_datatype=True\n",
    "    )\n",
    "    block_2_int_weight_2 = quant_bottleneck_model.quant_block2_conv2.quant_weight().int(\n",
    "        float_datatype=True\n",
    "    )\n",
    "    block_2_int_weight_3 = quant_bottleneck_model.quant_block2_conv3.quant_weight().int(\n",
    "        float_datatype=True\n",
    "    )\n",
    "\n",
    "    block_0_combined_scale1 = -torch.log2(\n",
    "        init_scale * block_0_weight_scale1 / block_0_relu_1\n",
    "    )  # RHS after first conv1x1 | clip 0-->255\n",
    "    block_0_combined_scale2 = -torch.log2(\n",
    "        block_0_relu_1 * block_0_weight_scale2 / block_0_relu_2\n",
    "    )  # RHS after second conv3x3 | clip 0-->255\n",
    "    block_0_combined_scale3 = -torch.log2(\n",
    "        block_0_relu_2 * block_0_weight_scale3 / init_scale\n",
    "    )  # RHS after third conv1x1 | clip -128-->+127\n",
    "    block_0_combined_scale_skip = -torch.log2(\n",
    "        init_scale * block_0_weight_scale_skip / init_scale\n",
    "    )  # LHS after conv1x1 | clip -128-->+127\n",
    "    block_0_combined_scale4 = -torch.log2(\n",
    "        init_scale / block_0_relu_3\n",
    "    )  # After addition | clip 0-->255\n",
    "\n",
    "    block_1_combined_scale1 = -torch.log2(\n",
    "        block_0_relu_3 * block_1_weight_scale1 / block_1_relu_1\n",
    "    )  # RHS after first conv1x1 | clip 0-->255\n",
    "    block_1_combined_scale2 = -torch.log2(\n",
    "        block_1_relu_1 * block_1_weight_scale2 / block_1_relu_2\n",
    "    )  # RHS after second conv3x3 | clip 0-->255\n",
    "    block_1_combined_scale3 = -torch.log2(\n",
    "        block_1_relu_2 * block_1_weight_scale3 / block_1_quant_add_1\n",
    "    )  # RHS after third conv1x1 | clip -128-->+127\n",
    "    block_1_combined_scale4 = -torch.log2(\n",
    "        block_1_quant_add_1 / block_1_relu_3\n",
    "    )  # After addition | clip 0-->255\n",
    "\n",
    "    block_2_combined_scale1 = -torch.log2(\n",
    "        block_1_relu_3 * block_2_weight_scale1 / block_2_relu_1\n",
    "    )  # RHS after first conv1x1 | clip 0-->255\n",
    "    block_2_combined_scale2 = -torch.log2(\n",
    "        block_2_relu_1 * block_2_weight_scale2 / block_2_relu_2\n",
    "    )  # RHS after second conv3x3 | clip 0-->255\n",
    "    block_2_combined_scale3 = -torch.log2(\n",
    "        block_2_relu_2 * block_2_weight_scale3 / block_2_quant_add_1\n",
    "    )  # RHS after third conv1x1 | clip -128-->+127\n",
    "    block_2_combined_scale4 = -torch.log2(\n",
    "        block_2_quant_add_1 / block_2_relu_3\n",
    "    )  # After addition | clip 0-->255\n",
    "\n",
    "    print(\"_________POST PTQ SCALES_________\")\n",
    "    print(\"init_scale:\", init_scale)\n",
    "    print(\"block_0_relu1:\", block_0_relu_1)\n",
    "    print(\"block_0_relu2:\", block_0_relu_2)\n",
    "    print(\"block_0_relu3:\", block_0_relu_3)\n",
    "\n",
    "    print(\"block_0_weight_scale1:\", block_0_weight_scale1)\n",
    "    print(\"block_0_weight_scale2:\", block_0_weight_scale2)\n",
    "    print(\"block_0_weight_scale3:\", block_0_weight_scale3)\n",
    "    print(\"block_0_weight_scale_skip:\", block_0_weight_scale_skip)\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "    print(\"block_1_quant_add_1:\", block_1_quant_add_1)\n",
    "    print(\"block_1_relu1:\", block_1_relu_1)\n",
    "    print(\"block_1_relu2:\", block_1_relu_2)\n",
    "    print(\"block_1_relu3:\", block_1_relu_3)\n",
    "    print(\"block_1_weight_scale1:\", block_1_weight_scale1)\n",
    "    print(\"block_1_weight_scale2:\", block_1_weight_scale2)\n",
    "    print(\"block_1_weight_scale3:\", block_1_weight_scale3)\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "    print(\"block_2_quant_add_1:\", block_2_quant_add_1)\n",
    "    print(\"block_2_relu1:\", block_2_relu_1)\n",
    "    print(\"block_2_relu2:\", block_2_relu_2)\n",
    "    print(\"block_2_relu3:\", block_2_relu_3)\n",
    "    print(\"block_2_weight_scale1:\", block_2_weight_scale1)\n",
    "    print(\"block_2_weight_scale2:\", block_2_weight_scale2)\n",
    "    print(\"block_2_weight_scale3:\", block_2_weight_scale3)\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "    print(\"combined_scale block0 after first conv1x1:\", block_0_combined_scale1.item())\n",
    "    print(\"combined_scale block0 after second conv3x3:\", block_0_combined_scale2.item())\n",
    "    print(\"combined_scale block0 after third conv1x1:\", block_0_combined_scale3.item())\n",
    "    print(\n",
    "        \"combined_scale block0 after adding skip connection:\",\n",
    "        (block_0_combined_scale4).item(),\n",
    "    )\n",
    "    print(\n",
    "        \"combined_scale block0 after skip conv1x1:\", block_0_combined_scale_skip.item()\n",
    "    )\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "    print(\"combined_scale block1 after first conv1x1:\", block_1_combined_scale1.item())\n",
    "    print(\"combined_scale block1 after second conv3x3:\", block_1_combined_scale2.item())\n",
    "    print(\"combined_scale block1 after third conv1x1:\", block_1_combined_scale3.item())\n",
    "    print(\n",
    "        \"combined_scale block1 after adding skip connection:\",\n",
    "        (block_1_combined_scale4).item(),\n",
    "    )\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "    print(\"combined_scale block2 after first conv1x1:\", block_2_combined_scale1.item())\n",
    "    print(\"combined_scale block2 after second conv3x3:\", block_2_combined_scale2.item())\n",
    "    print(\"combined_scale block2 after third conv1x1:\", block_2_combined_scale3.item())\n",
    "    print(\n",
    "        \"combined_scale block2 after adding skip connection:\",\n",
    "        (block_2_combined_scale4).item(),\n",
    "    )\n",
    "\n",
    "    q_bottleneck_out = quant_bottleneck_model(input)\n",
    "    gold_out = q_bottleneck_out.int(float_datatype=True).data.numpy().astype(dtype_out)\n",
    "    print(\"Golden::Brevitas::\", gold_out)\n",
    "    gold_out.tofile(log_folder + \"/gold_out.txt\", sep=\",\", format=\"%d\")\n",
    "\n",
    "    from brevitas.export import export_onnx_qcdq\n",
    "\n",
    "    # ref_input = torch.ones(1, 3, 32, 32, device=\"cpu\", dtype=dtype)\n",
    "    export_onnx_qcdq(quant_bottleneck_model, input, log_folder + \"/\" + design + \".onnx\")\n",
    "    # # Brevitas convolution\n",
    "    q_inp = quant_id_1(input)\n",
    "    int_inp = q_inp.int(float_datatype=True)\n",
    "\n",
    "    before_input = int_inp.squeeze().data.numpy().astype(dtype_in)\n",
    "\n",
    "    before_input.tofile(\n",
    "        log_folder + \"/before_ifm_mem_fmt_1x1.txt\", sep=\",\", format=\"%d\"\n",
    "    )\n",
    "    ifm_mem_fmt = ds.reorder_mat(before_input, \"YCXC8\", \"CYX\")\n",
    "    ifm_mem_fmt.tofile(log_folder + \"/after_ifm_mem_fmt_1x1.txt\", sep=\",\", format=\"%d\")\n",
    "    block0_wts1 = ds.reorder_mat(\n",
    "        block_0_int_weight_1.data.numpy().astype(dtype_wts), \"OIYXI8O8\", \"OIYX\"\n",
    "    )\n",
    "    block0_wts2 = ds.reorder_mat(\n",
    "        block_0_int_weight_2.data.numpy().astype(dtype_wts), \"OIYXI8O8\", \"OIYX\"\n",
    "    )\n",
    "    block0_wts3 = ds.reorder_mat(\n",
    "        block_0_int_weight_3.data.numpy().astype(dtype_wts), \"OIYXI8O8\", \"OIYX\"\n",
    "    )\n",
    "    block0_wts_skip = ds.reorder_mat(\n",
    "        block_0_int_weight_skip.data.numpy().astype(dtype_wts), \"OIYXI8O8\", \"OIYX\"\n",
    "    )\n",
    "\n",
    "    total_wts = np.concatenate(\n",
    "        (block0_wts1, block0_wts2, block0_wts3, block0_wts_skip), axis=None\n",
    "    )\n",
    "\n",
    "    block1_wts1 = ds.reorder_mat(\n",
    "        block_1_int_weight_1.data.numpy().astype(dtype_wts), \"OIYXI8O8\", \"OIYX\"\n",
    "    )\n",
    "    block1_wts2 = ds.reorder_mat(\n",
    "        block_1_int_weight_2.data.numpy().astype(dtype_wts), \"OIYXI8O8\", \"OIYX\"\n",
    "    )\n",
    "    block1_wts3 = ds.reorder_mat(\n",
    "        block_1_int_weight_3.data.numpy().astype(dtype_wts), \"OIYXI8O8\", \"OIYX\"\n",
    "    )\n",
    "\n",
    "    total_wts2 = np.concatenate(\n",
    "        (total_wts, block1_wts1, block1_wts2, block1_wts3), axis=None\n",
    "    )\n",
    "\n",
    "    block2_wts1 = ds.reorder_mat(\n",
    "        block_2_int_weight_1.data.numpy().astype(dtype_wts), \"OIYXI8O8\", \"OIYX\"\n",
    "    )\n",
    "    block2_wts2 = ds.reorder_mat(\n",
    "        block_2_int_weight_2.data.numpy().astype(dtype_wts), \"OIYXI8O8\", \"OIYX\"\n",
    "    )\n",
    "    block2_wts3 = ds.reorder_mat(\n",
    "        block_2_int_weight_3.data.numpy().astype(dtype_wts), \"OIYXI8O8\", \"OIYX\"\n",
    "    )\n",
    "\n",
    "    total_wts3 = np.concatenate(\n",
    "        (total_wts2, block2_wts1, block2_wts2, block2_wts3), axis=None\n",
    "    )\n",
    "\n",
    "    total_wts3.tofile(log_folder + \"/weights_mem_fmt_final.txt\", sep=\",\", format=\"%d\")\n",
    "    print(\"total_wts\", total_wts2.shape)\n",
    "    # for i in range (0,1):\n",
    "    app.buffers[2].write(ifm_mem_fmt)  # input's standard format CYX | scalar YCX\n",
    "    app.buffers[3].write(total_wts3)  # wts's standard format OIYX | scalar OIYX\n",
    "    # app.buffers[3].write(int_weight2.data.numpy().astype(dtype_in),offset=2048) # wts's standard format OIYX | scalar OIYX\n",
    "    app.run()\n",
    "    output3 = app.buffers[4].read()\n",
    "    if enable_trace:\n",
    "        output3, trace = extract_trace(output3, shape_out, dtype_out)\n",
    "        write_out_trace(trace, trace_file)\n",
    "    # temp_out=output3.reshape(32,256, 32)\n",
    "    # ofm_mem_fmt = temp_out.swapaxes(0,1)\n",
    "    temp_out = output3.reshape(32, 32, 32, 8)\n",
    "    temp2_out = ds.reorder_mat(temp_out, \"CDYX\", \"YCXD\")\n",
    "    ofm_mem_fmt = temp2_out.reshape(256, 32, 32)\n",
    "    ofm_mem_fmt.tofile(\n",
    "        log_folder + \"/after_ofm_mem_fmt_final.txt\", sep=\",\", format=\"%d\"\n",
    "    )\n",
    "\n",
    "    ofm_mem_fmt = torch.from_numpy(ofm_mem_fmt).unsqueeze(0)\n",
    "    print(\"AIE output:::\", ofm_mem_fmt)\n",
    "    print(type(ofm_mem_fmt))\n",
    "    print(type(q_bottleneck_out))\n",
    "    print(\n",
    "        \"difference::\",\n",
    "        torch.max(torch.abs(ofm_mem_fmt * block_2_relu_3 - q_bottleneck_out)),\n",
    "    )\n",
    "    diff = torch.abs(ofm_mem_fmt - gold_out)\n",
    "    # print(\"diff::\",diff)\n",
    "    # for i, x1 in enumerate(diff):\n",
    "    #     for j, x2 in enumerate(x1):\n",
    "    #         for k, x3 in enumerate(x2):\n",
    "    #             for l, x4 in enumerate(x3):\n",
    "    #                 if x4 > 3:\n",
    "    #                     print(\"i:\",i,\", j:\",j,\", k:\", k, \", l:\", l, \", val:\",x4)\n",
    "    #                     print(\"ofm_mem_fmt val:\",ofm_mem_fmt[i,j,k,l])\n",
    "    #                     print(\"gold_out val:\",gold_out[i,j,k,l])\n",
    "    sq_abs = torch.square(torch.abs(ofm_mem_fmt * block_2_relu_3 - q_bottleneck_out))\n",
    "    print(\"rms::\", torch.sqrt(torch.sum(sq_abs) / torch.numel(sq_abs)))\n",
    "    # assert(np.allclose(ofm_mem_fmt ,gold_out , rtol=0, atol=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e5c9e7e-997d-4e29-87e9-6dc4f69113a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2156134400 3690978303 3690978303 ... 3690978303 3690978303 3690978303]\n"
     ]
    }
   ],
   "source": [
    "if enable_trace:\n",
    "    print(trace)\n",
    "else:\n",
    "    print(\"tracing not enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31861e3-73d3-4197-b802-195c1573eedd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b36a4b-b6b2-4c32-9292-8a0994df8434",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
