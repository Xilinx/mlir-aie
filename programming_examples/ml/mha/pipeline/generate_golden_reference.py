import argparse
import torch
import numpy as np


# Map data types to PyTorch types
DTYPE_MAP = {
    "bf16": torch.bfloat16,
    "f32": torch.float32,
    "i8": torch.int8,
    "i16": torch.int16,
    "i32": torch.int32,
}

# Map data types to C++ types
CPP_DTYPE_MAP = {
    "bf16": "std::bfloat16_t",
    "f32": "float",
    "i8": "int8_t",
    "i16": "int16_t", 
    "i32": "int32_t",
}

def generate_random_data(heads, S_q, S_kv, num_kv_heads, d, dtype, seed=42, verbose: bool = False):
    """Generate random input matrices A and B."""
    torch.manual_seed(seed)
    np.random.seed(seed)
    
    torch_dtype = DTYPE_MAP[dtype]
    
    val_range = 4
    
    Q = torch.rand(heads, S_q, d, dtype=torch.float32) * val_range
    K = torch.rand(num_kv_heads, S_kv, d, dtype=torch.float32) * val_range
    V = torch.rand(num_kv_heads, S_kv, d, dtype=torch.float32) * val_range
    
    number_of_groups = heads // num_kv_heads
    
    K = K.repeat_interleave(number_of_groups, dim=0)
    V = V.repeat_interleave(number_of_groups, dim=0)

    return Q, K, V

def compute_golden_reference(Q, K, V, heads, num_kv_heads):
    """Compute the golden reference using PyTorch matmul."""
    inv_scale = 1 / np.sqrt(K.shape[-1])
    
    QK = (Q @ K.transpose(-1, -2)).to(torch.bfloat16)
    QK_scaled = QK * inv_scale
    
    A = torch.nn.functional.softmax(QK_scaled.to(torch.bfloat16), dim=-1).to(torch.bfloat16)
        
    O = (A @ V.to(torch.bfloat16)).to(torch.bfloat16)
    
    torch.set_printoptions(precision=6)
    
    X = torch.nn.functional.scaled_dot_product_attention(
        Q.to(torch.bfloat16),
        K.to(torch.bfloat16),
        V.to(torch.bfloat16),
        attn_mask=None,
        dropout_p=0.0,
        is_causal=False,
        scale=inv_scale
    ).to(torch.bfloat16)
    O = X # Use torch official sdpa function as golden model

    # Debug  
    # O = QK
    
    return QK, QK_scaled, A, O

def tensor_to_header(tensor: torch.tensor, cpp_dtype: str, name: str) -> str:
    ret = "\n"
    ret += f"// Tensor {name} {tensor.shape} of type {cpp_dtype}\n"
    ret += f"constexpr std::array<{cpp_dtype}, {np.prod(tensor.shape)}> {name} = {{\n"
        
    tensor_flat = tensor.flatten().to(torch.float32).numpy() if cpp_dtype == "std::bfloat16_t" else tensor.flatten().numpy()
    for i, val in enumerate(tensor_flat):
        if cpp_dtype == "std::bfloat16_t":
            ret += f"    {cpp_dtype}({float(val):.6f}f)"
        elif cpp_dtype == "float":
            ret += f"    {float(val):.6f}f"
        else:
            ret += f"    {int(val)}"
        
        if i < len(tensor_flat) - 1:
            ret += ","
        if (i + 1) % 8 == 0:
            ret += "\n"
        
    ret += "\n};"
    return ret

def export_to_header(Q, K, V, QK, QK_scaled, A, O, heads, S_q, S_kv, num_kv_heads, d, dtype, header_path, verbose: bool = False):
    """Export matrices to C++ header file."""
    cpp_dtype = CPP_DTYPE_MAP[dtype]
    
    header_str = f"""// Generated golden reference values for matrix multiplication
// Number of Heads: H={heads}
// Sequence Length for Query (Q): S_q={S_q}
// Sequence Length for Key/Value (KV): S_kv={S_kv}
// Embedding Dimension (d): d={d}
// Type: {dtype} ({cpp_dtype})
// Generated by generate_golden_reference.py

#ifndef GOLDEN_REFERENCE_H
#define GOLDEN_REFERENCE_H

#include <array>
#include <cstdint>
#include <stdfloat>

namespace golden_reference {{

// MHA parameters
constexpr int HEADS = {heads};
constexpr int num_kv_heads = {num_kv_heads};
constexpr int S_q = {S_q};
constexpr int S_kv = {S_kv};
constexpr int d = {d};
"""
    
    with open(header_path, 'w') as f:
        f.write(header_str)
    
        f.write(tensor_to_header(Q, cpp_dtype, "Q"))
        f.write(tensor_to_header(K, cpp_dtype, "K"))
        f.write(tensor_to_header(V, cpp_dtype, "V"))
        f.write(tensor_to_header(QK, cpp_dtype, "QK"))
        f.write(tensor_to_header(A, cpp_dtype, "A"))
        f.write(tensor_to_header(O, cpp_dtype, "O"))
        
        f.write("} // namespace golden_reference\n")
        f.write("#endif // GOLDEN_REFERENCE_H")


def main():
    parser = argparse.ArgumentParser(description="Generate PyTorch golden reference for matrix multiplication")
    parser.add_argument("--heads", type=int, default=1, help="Number of heads")
    parser.add_argument("--S_q", type=int, default=256, help="Sequence length for query (Q)")
    parser.add_argument("--S_kv", type=int, default=256, help="Sequence length for key/value (KV)")
    parser.add_argument("-d", type=int, default=256, help="Embedding dimension (d)")
    parser.add_argument("--num_KV_heads", type=int, default=2, help="Number of heads for Key-Value pairs")
    parser.add_argument("--dtype", type=str, choices=["bf16", "f32"], 
                       default="bf16", help="Input data type")
    parser.add_argument("--output", type=str, default="golden_reference.h", 
                       help="Output header file path")
    parser.add_argument("--seed", type=int, default=42, help="Random seed")
    parser.add_argument("--verbose", "-v", action="store_true", help="Verbose output")
    
    args = parser.parse_args()
    
    num_kv_heads = args.num_KV_heads
    if args.num_KV_heads == 0:
        num_kv_heads = args.heads
        
    if args.verbose:
        print(f"Generating golden reference for Multi-Head Attention with:")
        print(f"Heads: {args.heads}, S_q: {args.S_q}, S_kv: {args.S_kv}, d: {args.d}")
        print(f"Type: {args.dtype}")

    Q, K, V = generate_random_data(args.heads, args.S_q, args.S_kv, num_kv_heads, args.d, args.dtype, args.seed, args.verbose)
    
    if args.verbose:
        print("Generated input tensors Q, K, and V")

    QK, QK_scaled, A, O = compute_golden_reference(Q, K, V, args.heads, num_kv_heads)
    
    if args.verbose:
        print("Computed golden references using PyTorch")

    export_to_header(Q, K, V, QK, QK_scaled, A, O, args.heads, args.S_q, args.S_kv, num_kv_heads, args.d, args.dtype, args.output, args.verbose)
    
    if args.verbose:
        print(f"Exported golden reference to {args.output}")
    
    if args.verbose:
        print(f"Golden reference exported to: {args.output}")

if __name__ == "__main__":
    main()
