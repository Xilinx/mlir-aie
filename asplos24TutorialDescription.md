# ASPLOS'24 Tutorial: Levering MLIR to Design for AI Engines on RyzenAI

## Introduction

The AI Engine array in the NPU of the AMD Ryzen AI device includes a set of VLIW vector processors with adaptable interconnect. This tutorial is targeted at performance engineers and tool developers who are looking for fast and completely open source design tools to support their research. Participants will first get insight into the AI Engine compute and data movement capabilities. Through small design examples expressed in the MLIR-AIE python language bindings and executed on an Ryzen AI device, participants will leverage AI Engine features for optimizing performance of increasingly complex designs. This will enable them to recognize how this physical-level dialect can be connected to higher level abstraction in the MLIR framework and understand how logical concepts can be expressed to increase productivity and reduce complexity. The labs will be done on Ryzen AI enabled miniPcs giving participants the ability to execute their own designs on real hardware.


This tutorial will cover the following key topics:
1. AI Engine architecture introduction 
1. AIE core, array configuration and host application code compilation
1. Data movement and communication abstraction layers
1. Tracing for performance monitoring
1. Putting it all together on larger examples: matrix multiplication, convolutions as building blocks for ML and computer vision examples 

## Agenda

Date: Saturday April 27th 2024 (morning)  
Location: Hilton La Jolla Torrey Pines, San Diego, California (with ASPLOSâ€™24)  
Prerequisite: please bring your laptop, so that you can ssh into our RyzenAI enabled miniPCs for the hands-on excersizes.

### Contents and Timeline

| Time | Topic | Presenter | Slides or Code |
|------|-------|-----------|----------------|
| tbd | tbd | tbd | tbd |
| tbd | tbd | tbd | tbd |


## Organizers