//===- AIETransformOps.td ----------------------------------*- tablegen -*-===//
//
// This file is licensed under the Apache License v2.0 with LLVM Exceptions.
// See https://llvm.org/LICENSE.txt for license information.
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
//
// (c) Copyright 2023-2024 Advanced Micro Devices, Inc. or its affiliates
//
//===----------------------------------------------------------------------===//

#ifndef DIALECT_AIEVEC_TRANSFORMS_AIEVECTRANSFORMOPS
#define DIALECT_AIEVEC_TRANSFORMS_AIEVECTRANSFORMOPS

include "mlir/Dialect/PDL/IR/PDLTypes.td"
include "mlir/Dialect/Transform/IR/TransformAttrs.td"
include "mlir/Dialect/Transform/IR/TransformDialect.td"
include "mlir/Dialect/Transform/Interfaces/TransformInterfaces.td"
include "mlir/Dialect/Transform/IR/TransformTypes.td"
include "mlir/Interfaces/SideEffectInterfaces.td"
include "mlir/IR/OpBase.td"

def VectorizeContractionOp : Op<Transform_Dialect,
                        "structured.vectorize_contraction", [
                        FunctionalStyleTransformOpTrait,
                        MemoryEffectsOpInterface, TransformEachOpTrait,
                        TransformOpInterface]> {
  let description = [{
      Vectorize a LinalgOp describing a contraction by reinterpreting the
      scalar types as vector types, and replacing the payload with a
      `vector.contract` op.

      A contraction is any LinalgOp with GEMM-like semantics for the three
      innermost loops. This transformation will replace those three innermost
      loops with a single `vector.contract` op. This sort of LinalgOp is
      commonly produced by the `structured.pack` op applied on a
      `linalg.matmul` op.

      #### Example

      Consider the following `linalg.generic` and indexing maps generated by
      tiling a `linalg.matmul`:

      ```
      //                  T2  T1  T0   M   N   K      T2  T0   M   K
      #mapA = affine_map<(d0, d1, d2, d3, d4, d5) -> (d0, d2, d3, d5)>
      //                  T2  T1  T0   M   N   K      T0  T1   K   N
      #mapB = affine_map<(d0, d1, d2, d3, d4, d5) -> (d2, d1, d5, d4)>
      //                  T2  T1  T0   M   N   K      T2  T1   M   N
      #mapC = affine_map<(d0, d1, d2, d3, d4, d5) -> (d0, d1, d3, d4)>

      %r = linalg.generic
              {indexing_maps  = [#mapA, #mapB, #mapC],
               iterator_types = ["parallel", "parallel", "reduction",
                                 "parallel", "parallel", "reduction"]}
              ins(%A, %B : tensor<16x64x4x2xi8>, tensor<64x8x2x8xi8>)
              outs(%C : tensor<16x8x4x8xi32>) {
                  ^bb0(%a: i8, %b: i8, %acc: i32):
                      %0 = arith.extsi %a : i8 to i32
                      %1 = arith.extsi %b : i8 to i32
                      %2 = arith.muli %0, %1 : i32
                      %3 = arith.addi %acc, %2 : i32
                      linalg.yield %3 : i32
          } -> tensor<16x8x4x8xi32>
      ```

      This `linalg.generic`op represents a tiled matrix multiplication, with
      4x2 tiles for the lhs operand, 2x8 tiles for the rhs operand, and 4x8
      tiles for the accumulator.

      The purpose of this transformation is to replace this `linalg.generic`
      op with a vectorized version that replaces the scalar operations with
      tile-sized vector ones.

      That is:
      ```
      //                  T2  T1  T0      T2  T0
      #mapA = affine_map<(d0, d1, d2) -> (d0, d2)>
      //                  T2  T1  T0      T0  T1
      #mapB = affine_map<(d0, d1, d2) -> (d2, d1)>
      //                  T2  T1  T0      T2  T1
      #mapC = affine_map<(d0, d1, d2) -> (d0, d1)>

      #matmul_accesses = [
          //           M   N   K       M   K
          affine_map<(d0, d1, d2) -> (d0, d2)>,
          //           M   N   K       K   N
          affine_map<(d0, d1, d2) -> (d2, d1)>,
          //           M   N   K       M   N
          affine_map<(d0, d1, d2) -> (d0, d1)>
      ]

      #matmul_trait = {
          indexing_maps = #matmul_accesses,
          iterator_types = ["parallel", "parallel", "reduction"]
      }

      // Reinterpret A as tensor of vectors
      %Ab = bufferization.to_memref %A : memref<16x64x4x2xi8>
      %Av = vector.type_cast %Ab : memref<16x64x4x2xi8> to memref<16x64xvector<4x2xi8>>
      %At = bufferization.to_tensor %Av restrict : memref<16x64xvector<4x2xi8>>

      // Reinterpret B as tensor of vectors
      %Bb = bufferization.to_memref %B : memref<64x8x2x8xi8>
      %Bv = vector.type_cast %Bb : memref<64x8x2x8xi8> to memref<64x8xvector<2x8xi8>>
      %Bt = bufferization.to_tensor %Bv restrict : memref<64x8xvector<2x8xi8>>

      // Reinterpret C as tensor of vectors
      %Cb = bufferization.to_memref %C : memref<16x8x4x8xi32>
      %Cv = vector.type_cast %Cb : memref<16x8x4x8xi32> to memref<16x8xvector<4x8xi32>>
      %Ct = bufferization.to_tensor %Cv restrict : memref<16x8xvector<4x8xi32>>

      %rtv = linalg.generic
               {indexing_maps  = [#mapA, #mapB, #mapC],
                iterator_types = ["parallel", "parallel", "reduction"]}
              ins(%A, %B : tensor<16x64xvector<4x2xi8>>, tensor<64x8xvector<2x8xi8>>)
              outs(%C : tensor<16x8xvector<4x8>xi32>) {
                  ^bb0(%a: vector<4x2xi8>, %b: vector<2x8xi8>, %acc: vector<4x8xi32>):
                      %0 = arith.extsi %a : vector<4x2xi8> to vector<4x2xi32>
                      %1 = arith.extsi %b : vector<2x8xi8> to vector<2x8xi32>
                      %2 = vector.contract #matmul_trait %0, %1, %acc :
                              vector<4x2xi32>, vector<2x8xi32> into vector<4x8xi32>
                      linalg.yield %2 : vector<4x8xi32>
           }

      // Reinterpret result as tensor of scalars
      %rmv = bufferization.to_memref %rtv : memref<16x8xvector<4x8xi32>>
      %rms = vector.type_cast %rmv : memref<16x8xvector<4x8xi32>> to memref<16x8x4x8xi32>
      %rts = bufferization.to_tensor %rms restrict : memref<16x8x4x8xi32>
      ```

      Notice how the `affine_maps` describing the access patterns have been
      split between tile accesses, in the `linalg.generic` op, and matrix
      multiply accesses, in the `vector.contract` op.
      }];

  let arguments = (ins TransformHandleTypeInterface:$target);
  // TODO: Return all new ops generated neatly arranged
  let results = (outs TransformHandleTypeInterface:$transformed);
  let assemblyFormat = [{
    $target attr-dict `:` functional-type($target, results)
  }];
  let extraClassDeclaration = [{
      ::mlir::DiagnosedSilenceableFailure applyToOne(
        ::mlir::transform::TransformRewriter &rewriter,
        ::mlir::linalg::GenericOp target,
        ::mlir::transform::ApplyToEachResultList &results,
        TransformState &state);
  }];
}

#endif // DIALECT_AIEVEC_TRANSFORMS_AIEVECTRANSFORMOPS
