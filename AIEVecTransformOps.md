<!-- Autogenerated by mlir-tblgen; don't manually edit -->

### `transform.structured.vectorize_contraction` (transform::VectorizeContractionOp)

Syntax:

```
operation ::= `transform.structured.vectorize_contraction` $target attr-dict `:` functional-type($target, results)
```

Vectorize a LinalgOp describing a contraction by reinterpreting the
scalar types as vector types, and replacing the payload with a
`vector.contract` op.

A contraction is any LinalgOp with GEMM-like semantics for the three
innermost loops. This transformation will replace those three innermost
loops with a single `vector.contract` op. This sort of LinalgOp is
commonly produced by the `structured.pack` op applied on a
`linalg.matmul` op.

#### Example

Consider the following `linalg.generic` and indexing maps generated by
tiling a `linalg.matmul`:

```
//                  T2  T1  T0   M   N   K      T2  T0   M   K
#mapA = affine_map<(d0, d1, d2, d3, d4, d5) -> (d0, d2, d3, d5)>
//                  T2  T1  T0   M   N   K      T0  T1   K   N
#mapB = affine_map<(d0, d1, d2, d3, d4, d5) -> (d2, d1, d5, d4)>
//                  T2  T1  T0   M   N   K      T2  T1   M   N
#mapC = affine_map<(d0, d1, d2, d3, d4, d5) -> (d0, d1, d3, d4)>

%r = linalg.generic
        {indexing_maps  = [#mapA, #mapB, #mapC],
         iterator_types = ["parallel", "parallel", "reduction",
                           "parallel", "parallel", "reduction"]}
        ins(%A, %B : tensor<16x64x4x2xi8>, tensor<64x8x2x8xi8>)
        outs(%C : tensor<16x8x4x8xi32>) {
            ^bb0(%a: i8, %b: i8, %acc: i32):
                %0 = arith.extsi %a : i8 to i32
                %1 = arith.extsi %b : i8 to i32
                %2 = arith.muli %0, %1 : i32
                %3 = arith.addi %acc, %2 : i32
                linalg.yield %3 : i32
    } -> tensor<16x8x4x8xi32>
```

This `linalg.generic`op represents a tiled matrix multiplication, with
4x2 tiles for the lhs operand, 2x8 tiles for the rhs operand, and 4x8
tiles for the accumulator.

The purpose of this transformation is to replace this `linalg.generic`
op with a vectorized version that replaces the scalar operations with
tile-sized vector ones.

That is:
```
//                  T2  T1  T0      T2  T0
#mapA = affine_map<(d0, d1, d2) -> (d0, d2)>
//                  T2  T1  T0      T0  T1
#mapB = affine_map<(d0, d1, d2) -> (d2, d1)>
//                  T2  T1  T0      T2  T1
#mapC = affine_map<(d0, d1, d2) -> (d0, d1)>

#matmul_accesses = [
    //           M   N   K       M   K
    affine_map<(d0, d1, d2) -> (d0, d2)>,
    //           M   N   K       K   N
    affine_map<(d0, d1, d2) -> (d2, d1)>,
    //           M   N   K       M   N
    affine_map<(d0, d1, d2) -> (d0, d1)>
]

#matmul_trait = {
    indexing_maps = #matmul_accesses,
    iterator_types = ["parallel", "parallel", "reduction"]
}

// Reinterpret A as tensor of vectors
%Ab = bufferization.to_memref %A : memref<16x64x4x2xi8>
%Av = vector.type_cast %Ab : memref<16x64x4x2xi8> to memref<16x64xvector<4x2xi8>>
%At = bufferization.to_tensor %Av restrict : memref<16x64xvector<4x2xi8>>

// Reinterpret B as tensor of vectors
%Bb = bufferization.to_memref %B : memref<64x8x2x8xi8>
%Bv = vector.type_cast %Bb : memref<64x8x2x8xi8> to memref<64x8xvector<2x8xi8>>
%Bt = bufferization.to_tensor %Bv restrict : memref<64x8xvector<2x8xi8>>

// Reinterpret C as tensor of vectors
%Cb = bufferization.to_memref %C : memref<16x8x4x8xi32>
%Cv = vector.type_cast %Cb : memref<16x8x4x8xi32> to memref<16x8xvector<4x8xi32>>
%Ct = bufferization.to_tensor %Cv restrict : memref<16x8xvector<4x8xi32>>

%rtv = linalg.generic
         {indexing_maps  = [#mapA, #mapB, #mapC],
          iterator_types = ["parallel", "parallel", "reduction"]}
        ins(%A, %B : tensor<16x64xvector<4x2xi8>>, tensor<64x8xvector<2x8xi8>>)
        outs(%C : tensor<16x8xvector<4x8>xi32>) {
            ^bb0(%a: vector<4x2xi8>, %b: vector<2x8xi8>, %acc: vector<4x8xi32>):
                %0 = arith.extsi %a : vector<4x2xi8> to vector<4x2xi32>
                %1 = arith.extsi %b : vector<2x8xi8> to vector<2x8xi32>
                %2 = vector.contract #matmul_trait %0, %1, %acc :
                        vector<4x2xi32>, vector<2x8xi32> into vector<4x8xi32>
                linalg.yield %2 : vector<4x8xi32>
     }

// Reinterpret result as tensor of scalars
%rmv = bufferization.to_memref %rtv : memref<16x8xvector<4x8xi32>>
%rms = vector.type_cast %rmv : memref<16x8xvector<4x8xi32>> to memref<16x8x4x8xi32>
%rts = bufferization.to_tensor %rms restrict : memref<16x8x4x8xi32>
```

Notice how the `affine_maps` describing the access patterns have been
split between tile accesses, in the `linalg.generic` op, and matrix
multiply accesses, in the `vector.contract` op.

Traits: `FunctionalStyleTransformOpTrait`, `TransformEachOpTrait`

Interfaces: `MemoryEffectsOpInterface`, `TransformOpInterface`

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `target` | TransformHandleTypeInterface instance |

#### Results:

| Result | Description |
| :----: | ----------- |
| `transformed` | TransformHandleTypeInterface instance |

